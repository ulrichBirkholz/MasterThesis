\section{Zielsetzung und Forschungsfragen}
\label{sec:Questions}

Mögliche Forschungsfragen:

\begin{enumerate}
\item Wie können generative pre-trained language models, wie z. B. ChatGPT, verwendet werden, um Trainingsdaten für die automatische Bewertung von Freitextaufgaben zu generieren?
\item Welche prompt engineering Techniken sind am effektivsten, um Trainingsdaten mit unterschiedlichen Charakteristiken zu erzeugen, wie beispielsweise verschiedene Antwortarten, inhaltliche Richtigkeit oder Fehler in den Antworten?
\item Inwieweit beeinflussen verschiedene Hyperparameter wie Model Temperatur oder Bearbeitungszeit, des generativen pre-trained language models die Qualität und Vielfalt der erzeugten Trainingsdaten?
\item Inwiefern kann die Qualität der automatisch generierten Trainingsdaten gewährleistet werden, und welche Methoden sind am besten geeignet, um die Qualität der generierten Daten zu überprüfen und sicherzustellen?
\item Wie performant sind maschinelle Lernmodelle, die auf Basis der automatisch generierten Trainingsdaten trainiert wurden, im Vergleich zu Modellen, die mit manuell erstellten Trainingsdaten trainiert wurden?
\item Wie wirkt sich Data Augmentation, wie beispielsweise Paraphrasierung oder Textvervollständigung, auf die Qualität und Vielfalt der generierten Trainingsdaten aus und inwiefern kann dies zur Verbesserung der maschinellen Lernmodelle beitragen?
\item In welchem Ausmaß beeinflussen die Kosten für das Training von generativen Sprachmodellen die Rentabilität des Einsatzes von ChatGPT zur automatischen Bewertung von Freitextaufgaben im Vergleich zu manuellen Bewertungsmethoden?
\item Wie lassen sich durch die Kombination von automatisch generierten Trainingsdaten und manuell erstellten Trainingsdaten die Kosten und der Zeitaufwand für die Erstellung von Trainingsdaten minimieren, ohne die Qualität der maschinellen Lernmodelle zu beeinträchtigen?
\end{enumerate}