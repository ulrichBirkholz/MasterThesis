Model: davinci, Essay Set: 5, score 1 vs experts score 1
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|1004|184|146|057 | TP: 1004, 72.18%; FN: 387; Total: 1391
1|052|083|112|081 | TP: 83, 25.3%; FN: 245; Total: 328
2|000|004|010|028 | TP: 10, 23.81%; FN: 32; Total: 42
3|000|000|013|021 | TP: 21, 61.76%; FN: 13; Total: 34
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 1004 & 184 & 146 & 057 \\
    \hline
    1 & 052 & 083 & 112 & 081 \\
    \hline
    2 & 000 & 004 & 010 & 028 \\
    \hline
    3 & 000 & 000 & 013 & 021 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.9507575757575758
Recall: 0.7217828900071891
F1: 0.8205966489579077
-------------------------------------
Category: 1
Precision: 0.3062730627306273
Recall: 0.2530487804878049
F1: 0.2771285475792989
-------------------------------------
Category: 2
Precision: 0.03558718861209965
Recall: 0.23809523809523808
F1: 0.061919504643962855
-------------------------------------
Category: 3
Precision: 0.11229946524064172
Recall: 0.6176470588235294
F1: 0.19004524886877827
-------------------------------------
Weighted across categories
Accuracy: 0.6228412256267409
Precision: 0.7956959310274785
Recall: 0.6228412256267409
F1: 0.6915934595894399
###################################################

Model: davinci, Essay Set: 5, score 1 vs experts score 2
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|1003|189|142|057 | TP: 1003, 72.11%; FN: 388; Total: 1391
1|053|078|111|079 | TP: 78, 24.3%; FN: 243; Total: 321
2|000|004|016|028 | TP: 16, 33.33%; FN: 32; Total: 48
3|000|000|012|023 | TP: 23, 65.71%; FN: 12; Total: 35
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 1003 & 189 & 142 & 057 \\
    \hline
    1 & 053 & 078 & 111 & 079 \\
    \hline
    2 & 000 & 004 & 016 & 028 \\
    \hline
    3 & 000 & 000 & 012 & 023 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.9498106060606061
Recall: 0.7210639827462257
F1: 0.8197793216183082
-------------------------------------
Category: 1
Precision: 0.2878228782287823
Recall: 0.24299065420560748
F1: 0.2635135135135135
-------------------------------------
Category: 2
Precision: 0.05693950177935943
Recall: 0.3333333333333333
F1: 0.0972644376899696
-------------------------------------
Category: 3
Precision: 0.12299465240641712
Recall: 0.6571428571428571
F1: 0.2072072072072072
-------------------------------------
Weighted across categories
Accuracy: 0.6239554317548747
Precision: 0.7914293068865603
Recall: 0.6239554317548747
F1: 0.6890372253316297
###################################################

Model: davinci, Essay Set: 5, score 2 vs experts score 1
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|998|191|140|062 | TP: 998, 71.75%; FN: 393; Total: 1391
1|057|085|106|080 | TP: 85, 25.91%; FN: 243; Total: 328
2|000|004|014|024 | TP: 14, 33.33%; FN: 28; Total: 42
3|000|000|016|018 | TP: 18, 52.94%; FN: 16; Total: 34
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 998 & 191 & 140 & 062 \\
    \hline
    1 & 057 & 085 & 106 & 080 \\
    \hline
    2 & 000 & 004 & 014 & 024 \\
    \hline
    3 & 000 & 000 & 016 & 018 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.9459715639810427
Recall: 0.7174694464414091
F1: 0.8160261651676206
-------------------------------------
Category: 1
Precision: 0.30357142857142855
Recall: 0.25914634146341464
F1: 0.2796052631578948
-------------------------------------
Category: 2
Precision: 0.050724637681159424
Recall: 0.3333333333333333
F1: 0.0880503144654088
-------------------------------------
Category: 3
Precision: 0.09782608695652174
Recall: 0.5294117647058824
F1: 0.1651376146788991
-------------------------------------
Weighted across categories
Accuracy: 0.6211699164345403
Precision: 0.79157347955888
Recall: 0.6211699164345403
F1: 0.6886438519056153
###################################################

Model: davinci, Essay Set: 5, score 2 vs experts score 2
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|999|196|132|064 | TP: 999, 71.82%; FN: 392; Total: 1391
1|056|079|111|075 | TP: 79, 24.61%; FN: 242; Total: 321
2|000|004|018|026 | TP: 18, 37.5%; FN: 30; Total: 48
3|000|001|015|019 | TP: 19, 54.29%; FN: 16; Total: 35
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 999 & 196 & 132 & 064 \\
    \hline
    1 & 056 & 079 & 111 & 075 \\
    \hline
    2 & 000 & 004 & 018 & 026 \\
    \hline
    3 & 000 & 001 & 015 & 019 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.9469194312796209
Recall: 0.7181883537023724
F1: 0.8168438266557646
-------------------------------------
Category: 1
Precision: 0.28214285714285714
Recall: 0.24610591900311526
F1: 0.2628951747088186
-------------------------------------
Category: 2
Precision: 0.06521739130434782
Recall: 0.375
F1: 0.11111111111111109
-------------------------------------
Category: 3
Precision: 0.10326086956521739
Recall: 0.5428571428571428
F1: 0.1735159817351598
-------------------------------------
Weighted across categories
Accuracy: 0.6211699164345403
Precision: 0.7880096664457944
Recall: 0.6211699164345403
F1: 0.6863651847653277
###################################################

Model: davinci, Essay Set: 6, score 1 vs experts score 1
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|1003|266|117|129 | TP: 1003, 66.2%; FN: 512; Total: 1515
1|016|030|051|063 | TP: 30, 18.75%; FN: 130; Total: 160
2|003|001|020|047 | TP: 20, 28.17%; FN: 51; Total: 71
3|000|002|007|042 | TP: 42, 82.35%; FN: 9; Total: 51
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 1003 & 266 & 117 & 129 \\
    \hline
    1 & 016 & 030 & 051 & 063 \\
    \hline
    2 & 003 & 001 & 020 & 047 \\
    \hline
    3 & 000 & 002 & 007 & 042 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.9814090019569471
Recall: 0.662046204620462
F1: 0.7906976744186045
-------------------------------------
Category: 1
Precision: 0.10033444816053512
Recall: 0.1875
F1: 0.13071895424836602
-------------------------------------
Category: 2
Precision: 0.10256410256410256
Recall: 0.28169014084507044
F1: 0.15037593984962405
-------------------------------------
Category: 3
Precision: 0.1494661921708185
Recall: 0.8235294117647058
F1: 0.25301204819277107
-------------------------------------
Weighted across categories
Accuracy: 0.6093489148580968
Precision: 0.8446260304692396
Recall: 0.6093489148580968
F1: 0.6913758016756143
###################################################

Model: davinci, Essay Set: 6, score 1 vs experts score 2
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|1003|263|116|132 | TP: 1003, 66.25%; FN: 511; Total: 1514
1|017|033|052|059 | TP: 33, 20.5%; FN: 128; Total: 161
2|002|002|019|048 | TP: 19, 26.76%; FN: 52; Total: 71
3|000|001|008|042 | TP: 42, 82.35%; FN: 9; Total: 51
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 1003 & 263 & 116 & 132 \\
    \hline
    1 & 017 & 033 & 052 & 059 \\
    \hline
    2 & 002 & 002 & 019 & 048 \\
    \hline
    3 & 000 & 001 & 008 & 042 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.9814090019569471
Recall: 0.6624834874504624
F1: 0.7910094637223974
-------------------------------------
Category: 1
Precision: 0.11036789297658862
Recall: 0.20496894409937888
F1: 0.14347826086956522
-------------------------------------
Category: 2
Precision: 0.09743589743589744
Recall: 0.2676056338028169
F1: 0.14285714285714285
-------------------------------------
Category: 3
Precision: 0.1494661921708185
Recall: 0.8235294117647058
F1: 0.25301204819277107
-------------------------------------
Weighted across categories
Accuracy: 0.6104618809126322
Precision: 0.8448320446581575
Recall: 0.6104618809126322
F1: 0.692117306442069
###################################################

Model: davinci, Essay Set: 6, score 2 vs experts score 1
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|1008|262|126|119 | TP: 1008, 66.53%; FN: 507; Total: 1515
1|016|034|044|066 | TP: 34, 21.25%; FN: 126; Total: 160
2|002|002|022|045 | TP: 22, 30.99%; FN: 49; Total: 71
3|000|002|006|043 | TP: 43, 84.31%; FN: 8; Total: 51
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 1008 & 262 & 126 & 119 \\
    \hline
    1 & 016 & 034 & 044 & 066 \\
    \hline
    2 & 002 & 002 & 022 & 045 \\
    \hline
    3 & 000 & 002 & 006 & 043 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.9824561403508771
Recall: 0.6653465346534654
F1: 0.793388429752066
-------------------------------------
Category: 1
Precision: 0.11333333333333333
Recall: 0.2125
F1: 0.14782608695652175
-------------------------------------
Category: 2
Precision: 0.1111111111111111
Recall: 0.30985915492957744
F1: 0.16356877323420074
-------------------------------------
Category: 3
Precision: 0.1575091575091575
Recall: 0.8431372549019608
F1: 0.2654320987654321
-------------------------------------
Weighted across categories
Accuracy: 0.6160267111853088
Precision: 0.8472321880282517
Recall: 0.6160267111853088
F1: 0.6960412158731712
###################################################

Model: davinci, Essay Set: 6, score 2 vs experts score 2
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|1008|260|122|124 | TP: 1008, 66.58%; FN: 506; Total: 1514
1|017|037|047|060 | TP: 37, 22.98%; FN: 124; Total: 161
2|001|002|021|047 | TP: 21, 29.58%; FN: 50; Total: 71
3|000|001|008|042 | TP: 42, 82.35%; FN: 9; Total: 51
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 1008 & 260 & 122 & 124 \\
    \hline
    1 & 017 & 037 & 047 & 060 \\
    \hline
    2 & 001 & 002 & 021 & 047 \\
    \hline
    3 & 000 & 001 & 008 & 042 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.9824561403508771
Recall: 0.665785997357992
F1: 0.7937007874015747
-------------------------------------
Category: 1
Precision: 0.12333333333333334
Recall: 0.22981366459627328
F1: 0.16052060737527116
-------------------------------------
Category: 2
Precision: 0.10606060606060606
Recall: 0.29577464788732394
F1: 0.15613382899628253
-------------------------------------
Category: 3
Precision: 0.15384615384615385
Recall: 0.8235294117647058
F1: 0.25925925925925924
-------------------------------------
Weighted across categories
Accuracy: 0.6165831942125766
Precision: 0.8473409682995834
Recall: 0.6165831942125766
F1: 0.6966135414548476
###################################################

Model: davinci, score 1 vs experts score 1
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|2007|450|263|186 | TP: 2007, 69.06%; FN: 899; Total: 2906
1|068|113|163|144 | TP: 113, 23.16%; FN: 375; Total: 488
2|003|005|030|075 | TP: 30, 26.55%; FN: 83; Total: 113
3|000|002|020|063 | TP: 63, 74.12%; FN: 22; Total: 85
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 2007 & 450 & 263 & 186 \\
    \hline
    1 & 068 & 113 & 163 & 144 \\
    \hline
    2 & 003 & 005 & 030 & 075 \\
    \hline
    3 & 000 & 002 & 020 & 063 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.965832531280077
Recall: 0.6906400550584997
F1: 0.8053772070626003
-------------------------------------
Category: 1
Precision: 0.19824561403508772
Recall: 0.23155737704918034
F1: 0.21361058601134217
-------------------------------------
Category: 2
Precision: 0.06302521008403361
Recall: 0.26548672566371684
F1: 0.10186757215619695
-------------------------------------
Category: 3
Precision: 0.1346153846153846
Recall: 0.7411764705882353
F1: 0.2278481012658228
-------------------------------------
Weighted across categories
Accuracy: 0.6160913140311804
Precision: 0.8134792182574694
Recall: 0.6160913140311804
F1: 0.68918325555643
###################################################

Model: davinci, score 1 vs experts score 2
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|2006|452|258|189 | TP: 2006, 69.05%; FN: 899; Total: 2905
1|070|111|163|138 | TP: 111, 23.03%; FN: 371; Total: 482
2|002|006|035|076 | TP: 35, 29.41%; FN: 84; Total: 119
3|000|001|020|065 | TP: 65, 75.58%; FN: 21; Total: 86
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 2006 & 452 & 258 & 189 \\
    \hline
    1 & 070 & 111 & 163 & 138 \\
    \hline
    2 & 002 & 006 & 035 & 076 \\
    \hline
    3 & 000 & 001 & 020 & 065 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.9653512993262753
Recall: 0.6905335628227195
F1: 0.8051374673891231
-------------------------------------
Category: 1
Precision: 0.19473684210526315
Recall: 0.23029045643153526
F1: 0.21102661596958175
-------------------------------------
Category: 2
Precision: 0.07352941176470588
Recall: 0.29411764705882354
F1: 0.11764705882352941
-------------------------------------
Category: 3
Precision: 0.1388888888888889
Recall: 0.7558139534883721
F1: 0.23465703971119134
-------------------------------------
Weighted across categories
Accuracy: 0.6172048997772829
Precision: 0.8126122290874195
Recall: 0.6172048997772829
F1: 0.6889809791419552
###################################################

Model: davinci, score 2 vs experts score 1
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|2006|453|266|181 | TP: 2006, 69.03%; FN: 900; Total: 2906
1|073|119|150|146 | TP: 119, 24.39%; FN: 369; Total: 488
2|002|006|036|069 | TP: 36, 31.86%; FN: 77; Total: 113
3|000|002|022|061 | TP: 61, 71.76%; FN: 24; Total: 85
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 2006 & 453 & 266 & 181 \\
    \hline
    1 & 073 & 119 & 150 & 146 \\
    \hline
    2 & 002 & 006 & 036 & 069 \\
    \hline
    3 & 000 & 002 & 022 & 061 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.9639596347909659
Recall: 0.6902959394356504
F1: 0.8044916783637458
-------------------------------------
Category: 1
Precision: 0.20517241379310344
Recall: 0.24385245901639344
F1: 0.22284644194756553
-------------------------------------
Category: 2
Precision: 0.0759493670886076
Recall: 0.3185840707964602
F1: 0.12265758091993186
-------------------------------------
Category: 3
Precision: 0.13347921225382933
Recall: 0.7176470588235294
F1: 0.22509225092250926
-------------------------------------
Weighted across categories
Accuracy: 0.6185968819599109
Precision: 0.8132847572817843
Recall: 0.6185968819599109
F1: 0.6903104200912646
###################################################

Model: davinci, score 2 vs experts score 2
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|2007|456|254|188 | TP: 2007, 69.09%; FN: 898; Total: 2905
1|073|116|158|135 | TP: 116, 24.07%; FN: 366; Total: 482
2|001|006|039|073 | TP: 39, 32.77%; FN: 80; Total: 119
3|000|002|023|061 | TP: 61, 70.93%; FN: 25; Total: 86
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 2007 & 456 & 254 & 188 \\
    \hline
    1 & 073 & 116 & 158 & 135 \\
    \hline
    2 & 001 & 006 & 039 & 073 \\
    \hline
    3 & 000 & 002 & 023 & 061 \\
    \hline
\end{tabular}
-------------------------------------
Category: 0
Precision: 0.964440172993753
Recall: 0.6908777969018933
F1: 0.8050541516245487
-------------------------------------
Category: 1
Precision: 0.2
Recall: 0.24066390041493776
F1: 0.2184557438794727
-------------------------------------
Category: 2
Precision: 0.08227848101265822
Recall: 0.3277310924369748
F1: 0.1315345699831366
-------------------------------------
Category: 3
Precision: 0.13347921225382933
Recall: 0.7093023255813954
F1: 0.22467771639042358
-------------------------------------
Weighted across categories
Accuracy: 0.6188752783964365
Precision: 0.8127419415482149
Recall: 0.6188752783964365
F1: 0.690131647120487
###################################################

