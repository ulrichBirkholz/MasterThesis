Key: bert_5_50_A_gpt4
Path: ../models/bert_v1/5_50_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|309|144|000 | TP: 144, 31.79%; FN: 309; Total: 453
2|184|141|000 | TP: 0, 0.0%; FN: 325; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 309 & 144 & 000 \\
    \hline
    2 & 184 & 141 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.5052631578947369
Recall: 0.31788079470198677
F1 Score: 0.39024390243902435
------------------------------------------
Performance for category: 2
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 778
Accuracy: 0.18508997429305912
Precision (Weighted): 0.2941956433500203
Recall (Weighted): 0.18508997429305912
F1 Score (Weighted): 0.22722427738416198
###################################################

Key: xgb_5_50_A_gpt4
Path: ../models/xgb_v1/5_50_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|011|037|405 | TP: 37, 8.17%; FN: 416; Total: 453
2|005|027|293 | TP: 293, 90.15%; FN: 32; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 011 & 037 & 405 \\
    \hline
    2 & 005 & 027 & 293 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.578125
Recall: 0.08167770419426049
F1 Score: 0.14313346228239845
------------------------------------------
Performance for category: 2
Precision: 0.4197707736389685
Recall: 0.9015384615384615
F1 Score: 0.5728250244379277
------------------------------------------
Number of Samples: 778
Accuracy: 0.4241645244215938
Precision (Weighted): 0.5119744555689778
Recall (Weighted): 0.4241645244215938
F1 Score (Weighted): 0.32263186549646916
###################################################

Key: bert_5_50_B_gpt4
Path: ../models/bert_v1/5_50_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|271|182|000 | TP: 182, 40.18%; FN: 271; Total: 453
2|159|166|000 | TP: 0, 0.0%; FN: 325; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 271 & 182 & 000 \\
    \hline
    2 & 159 & 166 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.5229885057471264
Recall: 0.40176600441501104
F1 Score: 0.4544319600499376
------------------------------------------
Performance for category: 2
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 778
Accuracy: 0.23393316195372751
Precision (Weighted): 0.30451644357769697
Recall (Weighted): 0.23393316195372751
F1 Score (Weighted): 0.2645985577154521
###################################################

Key: xgb_5_50_B_gpt4
Path: ../models/xgb_v1/5_50_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|046|007|117|283 | TP: 117, 25.83%; FN: 336; Total: 453
3|029|002|056|238 | TP: 238, 73.23%; FN: 87; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 046 & 007 & 117 & 283 \\
    \hline
    3 & 029 & 002 & 056 & 238 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6763005780346821
Recall: 0.2582781456953642
F1 Score: 0.3738019169329073
------------------------------------------
Performance for category: 3
Precision: 0.45681381957773515
Recall: 0.7323076923076923
F1 Score: 0.5626477541371159
------------------------------------------
Number of Samples: 778
Accuracy: 0.45629820051413883
Precision (Weighted): 0.5846126647975256
Recall (Weighted): 0.45629820051413883
F1 Score (Weighted): 0.452689959466799
###################################################

Key: bert_5_50_C_gpt4
Path: ../models/bert_v1/5_50_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|156|297|000 | TP: 297, 65.56%; FN: 156; Total: 453
2|080|245|000 | TP: 0, 0.0%; FN: 325; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 156 & 297 & 000 \\
    \hline
    2 & 080 & 245 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.5479704797047971
Recall: 0.6556291390728477
F1 Score: 0.5969849246231156
------------------------------------------
Performance for category: 2
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 778
Accuracy: 0.38174807197943444
Precision (Weighted): 0.3190625029643613
Recall (Weighted): 0.38174807197943444
F1 Score (Weighted): 0.34760176202348503
###################################################

Key: xgb_5_50_C_gpt4
Path: ../models/xgb_v1/5_50_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|056|001|094|302 | TP: 94, 20.75%; FN: 359; Total: 453
3|036|000|054|235 | TP: 235, 72.31%; FN: 90; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 056 & 001 & 094 & 302 \\
    \hline
    3 & 036 & 000 & 054 & 235 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6351351351351351
Recall: 0.20750551876379691
F1 Score: 0.31281198003327787
------------------------------------------
Performance for category: 3
Precision: 0.4376163873370577
Recall: 0.7230769230769231
F1 Score: 0.5452436194895591
------------------------------------------
Number of Samples: 778
Accuracy: 0.42287917737789205
Precision (Weighted): 0.5526240901038046
Recall (Weighted): 0.42287917737789205
F1 Score (Weighted): 0.4099074592405933
###################################################

Key: bert_5_50_D_gpt4
Path: ../models/bert_v1/5_50_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|159|294|000 | TP: 294, 64.9%; FN: 159; Total: 453
2|079|246|000 | TP: 0, 0.0%; FN: 325; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 159 & 294 & 000 \\
    \hline
    2 & 079 & 246 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.5444444444444444
Recall: 0.6490066225165563
F1 Score: 0.59214501510574
------------------------------------------
Performance for category: 2
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 778
Accuracy: 0.37789203084832906
Precision (Weighted): 0.3170094258783205
Recall (Weighted): 0.37789203084832906
F1 Score (Weighted): 0.34478366560784096
###################################################

Key: xgb_5_50_D_gpt4
Path: ../models/xgb_v1/5_50_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|007|000|224|222 | TP: 224, 49.45%; FN: 229; Total: 453
3|003|001|110|211 | TP: 211, 64.92%; FN: 114; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 007 & 000 & 224 & 222 \\
    \hline
    3 & 003 & 001 & 110 & 211 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6706586826347305
Recall: 0.49448123620309054
F1 Score: 0.5692503176620076
------------------------------------------
Performance for category: 3
Precision: 0.48729792147806006
Recall: 0.6492307692307693
F1 Score: 0.5567282321899736
------------------------------------------
Number of Samples: 778
Accuracy: 0.5591259640102828
Precision (Weighted): 0.5940619636425482
Recall (Weighted): 0.5591259640102828
F1 Score (Weighted): 0.5640193693607081
###################################################

Key: bert_5_50_E_gpt4
Path: ../models/bert_v1/5_50_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|306|147|000 | TP: 147, 32.45%; FN: 306; Total: 453
2|180|145|000 | TP: 0, 0.0%; FN: 325; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 306 & 147 & 000 \\
    \hline
    2 & 180 & 145 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.5034246575342466
Recall: 0.32450331125827814
F1 Score: 0.39463087248322143
------------------------------------------
Performance for category: 2
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 778
Accuracy: 0.18894601542416453
Precision (Weighted): 0.2931251540655703
Recall (Weighted): 0.18894601542416453
F1 Score (Weighted): 0.22977864426079606
###################################################

Key: xgb_5_50_E_gpt4
Path: ../models/xgb_v1/5_50_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|016|002|208|227 | TP: 208, 45.92%; FN: 245; Total: 453
3|004|000|115|206 | TP: 206, 63.38%; FN: 119; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 016 & 002 & 208 & 227 \\
    \hline
    3 & 004 & 000 & 115 & 206 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6439628482972136
Recall: 0.45916114790286977
F1 Score: 0.5360824742268041
------------------------------------------
Performance for category: 3
Precision: 0.47575057736720555
Recall: 0.6338461538461538
F1 Score: 0.5435356200527705
------------------------------------------
Number of Samples: 778
Accuracy: 0.532133676092545
Precision (Weighted): 0.5736942261220818
Recall (Weighted): 0.532133676092545
F1 Score (Weighted): 0.5391959348867514
###################################################

Key: bert_5_50_F_gpt4
Path: ../models/bert_v1/5_50_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|277|176|000 | TP: 176, 38.85%; FN: 277; Total: 453
2|154|171|000 | TP: 0, 0.0%; FN: 325; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 277 & 176 & 000 \\
    \hline
    2 & 154 & 171 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.5072046109510087
Recall: 0.38852097130242824
F1 Score: 0.44
------------------------------------------
Performance for category: 2
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 778
Accuracy: 0.2262210796915167
Precision (Weighted): 0.2953260780987236
Recall (Weighted): 0.2262210796915167
F1 Score (Weighted): 0.2561953727506427
###################################################

Key: xgb_5_50_F_gpt4
Path: ../models/xgb_v1/5_50_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|096|002|070|285 | TP: 70, 15.45%; FN: 383; Total: 453
3|042|002|028|253 | TP: 253, 77.85%; FN: 72; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 096 & 002 & 070 & 285 \\
    \hline
    3 & 042 & 002 & 028 & 253 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.7142857142857143
Recall: 0.1545253863134658
F1 Score: 0.2540834845735027
------------------------------------------
Performance for category: 3
Precision: 0.47026022304832715
Recall: 0.7784615384615384
F1 Score: 0.5863267670915411
------------------------------------------
Number of Samples: 778
Accuracy: 0.41516709511568123
Precision (Weighted): 0.6123470450670114
Recall (Weighted): 0.41516709511568123
F1 Score (Weighted): 0.392874058890164
###################################################

Key: bert_5_100_A_gpt4
Path: ../models/bert_v1/5_100_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|000|027|423|003 | TP: 423, 93.38%; FN: 30; Total: 453
3|001|012|305|007 | TP: 7, 2.15%; FN: 318; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 000 & 027 & 423 & 003 \\
    \hline
    3 & 001 & 012 & 305 & 007 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.5810439560439561
Recall: 0.9337748344370861
F1 Score: 0.716342082980525
------------------------------------------
Performance for category: 3
Precision: 0.7
Recall: 0.021538461538461538
F1 Score: 0.041791044776119404
------------------------------------------
Number of Samples: 778
Accuracy: 0.5526992287917738
Precision (Weighted): 0.6307363908584988
Recall (Weighted): 0.5526992287917738
F1 Score (Weighted): 0.43455662357637104
###################################################

Key: xgb_5_100_A_gpt4
Path: ../models/xgb_v1/5_100_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|041|006|196|210 | TP: 196, 43.27%; FN: 257; Total: 453
3|020|004|142|159 | TP: 159, 48.92%; FN: 166; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 041 & 006 & 196 & 210 \\
    \hline
    3 & 020 & 004 & 142 & 159 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.5798816568047337
Recall: 0.4326710816777042
F1 Score: 0.49557522123893816
------------------------------------------
Performance for category: 3
Precision: 0.43089430894308944
Recall: 0.48923076923076925
F1 Score: 0.4582132564841499
------------------------------------------
Number of Samples: 778
Accuracy: 0.45629820051413883
Precision (Weighted): 0.5176440114897795
Recall (Weighted): 0.45629820051413883
F1 Score (Weighted): 0.47996771668198934
###################################################

Key: bert_5_100_B_gpt4
Path: ../models/bert_v1/5_100_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|000|129|318|006 | TP: 318, 70.2%; FN: 135; Total: 453
3|001|060|256|008 | TP: 8, 2.46%; FN: 317; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 000 & 129 & 318 & 006 \\
    \hline
    3 & 001 & 060 & 256 & 008 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.554006968641115
Recall: 0.7019867549668874
F1 Score: 0.6192794547224927
------------------------------------------
Performance for category: 3
Precision: 0.5714285714285714
Recall: 0.024615384615384615
F1 Score: 0.04719764011799411
------------------------------------------
Number of Samples: 778
Accuracy: 0.4190231362467866
Precision (Weighted): 0.5612846304739213
Recall (Weighted): 0.4190231362467866
F1 Score (Weighted): 0.3802992622463204
###################################################

Key: xgb_5_100_B_gpt4
Path: ../models/xgb_v1/5_100_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|020|018|332|083 | TP: 332, 73.29%; FN: 121; Total: 453
3|013|021|188|103 | TP: 103, 31.69%; FN: 222; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 020 & 018 & 332 & 083 \\
    \hline
    3 & 013 & 021 & 188 & 103 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6384615384615384
Recall: 0.7328918322295805
F1 Score: 0.6824254881808838
------------------------------------------
Performance for category: 3
Precision: 0.553763440860215
Recall: 0.3169230769230769
F1 Score: 0.4031311154598826
------------------------------------------
Number of Samples: 778
Accuracy: 0.5591259640102828
Precision (Weighted): 0.6030799424198545
Recall (Weighted): 0.5591259640102828
F1 Score (Weighted): 0.5657536743835503
###################################################

Key: bert_5_100_C_gpt4
Path: ../models/bert_v1/5_100_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|000|048|395|010 | TP: 395, 87.2%; FN: 58; Total: 453
3|001|017|283|024 | TP: 24, 7.38%; FN: 301; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 000 & 048 & 395 & 010 \\
    \hline
    3 & 001 & 017 & 283 & 024 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.5825958702064897
Recall: 0.8719646799116998
F1 Score: 0.6984969053934571
------------------------------------------
Performance for category: 3
Precision: 0.7058823529411765
Recall: 0.07384615384615385
F1 Score: 0.13370473537604458
------------------------------------------
Number of Samples: 778
Accuracy: 0.538560411311054
Precision (Weighted): 0.6340972929427021
Recall (Weighted): 0.538560411311054
F1 Score (Weighted): 0.46256187293117035
###################################################

Key: xgb_5_100_C_gpt4
Path: ../models/xgb_v1/5_100_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|035|083|335 | TP: 83, 18.32%; FN: 370; Total: 453
2|021|043|261 | TP: 261, 80.31%; FN: 64; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 035 & 083 & 335 \\
    \hline
    2 & 021 & 043 & 261 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.6587301587301587
Recall: 0.18322295805739514
F1 Score: 0.28670120898100176
------------------------------------------
Performance for category: 2
Precision: 0.43791946308724833
Recall: 0.803076923076923
F1 Score: 0.5667752442996743
------------------------------------------
Number of Samples: 778
Accuracy: 0.442159383033419
Precision (Weighted): 0.5664891868998941
Recall (Weighted): 0.442159383033419
F1 Score (Weighted): 0.40369871730821066
###################################################

Key: bert_5_100_D_gpt4
Path: ../models/bert_v1/5_100_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|015|437|001 | TP: 437, 96.47%; FN: 16; Total: 453
2|007|318|000 | TP: 0, 0.0%; FN: 325; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 015 & 437 & 001 \\
    \hline
    2 & 007 & 318 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.5788079470198676
Recall: 0.9646799116997793
F1 Score: 0.7235099337748346
------------------------------------------
Performance for category: 2
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 778
Accuracy: 0.5616966580976864
Precision (Weighted): 0.3370179948586119
Recall (Weighted): 0.5616966580976864
F1 Score (Weighted): 0.4212724935732649
###################################################

Key: xgb_5_100_D_gpt4
Path: ../models/xgb_v1/5_100_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|017|024|283|129 | TP: 283, 62.47%; FN: 170; Total: 453
3|008|011|179|127 | TP: 127, 39.08%; FN: 198; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 017 & 024 & 283 & 129 \\
    \hline
    3 & 008 & 011 & 179 & 127 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6125541125541125
Recall: 0.6247240618101545
F1 Score: 0.6185792349726776
------------------------------------------
Performance for category: 3
Precision: 0.49609375
Recall: 0.39076923076923076
F1 Score: 0.43717728055077454
------------------------------------------
Number of Samples: 778
Accuracy: 0.5269922879177378
Precision (Weighted): 0.5639042181709678
Recall (Weighted): 0.5269922879177378
F1 Score (Weighted): 0.5428007835753531
###################################################

Key: bert_5_100_E_gpt4
Path: ../models/bert_v1/5_100_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|000|061|383|009 | TP: 383, 84.55%; FN: 70; Total: 453
3|001|029|280|015 | TP: 15, 4.62%; FN: 310; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 000 & 061 & 383 & 009 \\
    \hline
    3 & 001 & 029 & 280 & 015 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.5776772247360482
Recall: 0.8454746136865342
F1 Score: 0.6863799283154123
------------------------------------------
Performance for category: 3
Precision: 0.625
Recall: 0.046153846153846156
F1 Score: 0.08595988538681948
------------------------------------------
Number of Samples: 778
Accuracy: 0.5115681233933161
Precision (Weighted): 0.5974457362537658
Recall (Weighted): 0.5115681233933161
F1 Score (Weighted): 0.4355617869892006
###################################################

Key: xgb_5_100_E_gpt4
Path: ../models/xgb_v1/5_100_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|033|011|195|214 | TP: 195, 43.05%; FN: 258; Total: 453
3|020|007|093|205 | TP: 205, 63.08%; FN: 120; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 033 & 011 & 195 & 214 \\
    \hline
    3 & 020 & 007 & 093 & 205 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6770833333333334
Recall: 0.4304635761589404
F1 Score: 0.5263157894736843
------------------------------------------
Performance for category: 3
Precision: 0.4892601431980907
Recall: 0.6307692307692307
F1 Score: 0.5510752688172043
------------------------------------------
Number of Samples: 778
Accuracy: 0.5141388174807198
Precision (Weighted): 0.5986224891251665
Recall (Weighted): 0.5141388174807198
F1 Score (Weighted): 0.5366587596364658
###################################################

Key: bert_5_100_F_gpt4
Path: ../models/bert_v1/5_100_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|000|085|364|004 | TP: 364, 80.35%; FN: 89; Total: 453
3|001|036|281|007 | TP: 7, 2.15%; FN: 318; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 000 & 085 & 364 & 004 \\
    \hline
    3 & 001 & 036 & 281 & 007 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.5643410852713179
Recall: 0.8035320088300221
F1 Score: 0.663023679417122
------------------------------------------
Performance for category: 3
Precision: 0.6363636363636364
Recall: 0.021538461538461538
F1 Score: 0.041666666666666664
------------------------------------------
Number of Samples: 778
Accuracy: 0.4768637532133676
Precision (Weighted): 0.5944276265373892
Recall (Weighted): 0.4768637532133676
F1 Score (Weighted): 0.4034593746049139
###################################################

Key: xgb_5_100_F_gpt4
Path: ../models/xgb_v1/5_100_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|025|007|206|215 | TP: 206, 45.47%; FN: 247; Total: 453
3|015|005|119|186 | TP: 186, 57.23%; FN: 139; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 025 & 007 & 206 & 215 \\
    \hline
    3 & 015 & 005 & 119 & 186 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6338461538461538
Recall: 0.45474613686534215
F1 Score: 0.5295629820051414
------------------------------------------
Performance for category: 3
Precision: 0.46384039900249374
Recall: 0.5723076923076923
F1 Score: 0.5123966942148761
------------------------------------------
Number of Samples: 778
Accuracy: 0.5038560411311054
Precision (Weighted): 0.5628283256659616
Recall (Weighted): 0.5038560411311054
F1 Score (Weighted): 0.522391974894812
###################################################

Key: bert_5_200_A_gpt4
Path: ../models/bert_v1/5_200_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|001|026|426 | TP: 26, 5.74%; FN: 427; Total: 453
2|000|009|316 | TP: 316, 97.23%; FN: 9; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 001 & 026 & 426 \\
    \hline
    2 & 000 & 009 & 316 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.7428571428571429
Recall: 0.05739514348785872
F1 Score: 0.10655737704918034
------------------------------------------
Performance for category: 2
Precision: 0.42587601078167114
Recall: 0.9723076923076923
F1 Score: 0.5923149015932521
------------------------------------------
Number of Samples: 778
Accuracy: 0.43958868894601544
Precision (Weighted): 0.6104421455248443
Recall (Weighted): 0.43958868894601544
F1 Score (Weighted): 0.3094766514409841
###################################################

Key: xgb_5_200_A_gpt4
Path: ../models/xgb_v1/5_200_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|030|004|201|218 | TP: 201, 44.37%; FN: 252; Total: 453
3|012|009|101|203 | TP: 203, 62.46%; FN: 122; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 030 & 004 & 201 & 218 \\
    \hline
    3 & 012 & 009 & 101 & 203 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6655629139072847
Recall: 0.44370860927152317
F1 Score: 0.5324503311258277
------------------------------------------
Performance for category: 3
Precision: 0.4821852731591449
Recall: 0.6246153846153846
F1 Score: 0.5442359249329758
------------------------------------------
Number of Samples: 778
Accuracy: 0.519280205655527
Precision (Weighted): 0.5889591436718793
Recall (Weighted): 0.519280205655527
F1 Score (Weighted): 0.5373736190272713
###################################################

Key: bert_5_200_B_gpt4
Path: ../models/bert_v1/5_200_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|003|001|010|439 | TP: 10, 2.21%; FN: 443; Total: 453
3|001|000|002|322 | TP: 322, 99.08%; FN: 3; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 003 & 001 & 010 & 439 \\
    \hline
    3 & 001 & 000 & 002 & 322 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.8333333333333334
Recall: 0.02207505518763797
F1 Score: 0.043010752688172046
------------------------------------------
Performance for category: 3
Precision: 0.4231274638633377
Recall: 0.9907692307692307
F1 Score: 0.5930018416206262
------------------------------------------
Number of Samples: 778
Accuracy: 0.4267352185089974
Precision (Weighted): 0.6619748403028083
Recall (Weighted): 0.4267352185089974
F1 Score (Weighted): 0.27276281426021265
###################################################

Key: xgb_5_200_B_gpt4
Path: ../models/xgb_v1/5_200_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|044|030|063|316 | TP: 63, 13.91%; FN: 390; Total: 453
3|020|009|038|258 | TP: 258, 79.38%; FN: 67; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 044 & 030 & 063 & 316 \\
    \hline
    3 & 020 & 009 & 038 & 258 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6237623762376238
Recall: 0.1390728476821192
F1 Score: 0.22743682310469313
------------------------------------------
Performance for category: 3
Precision: 0.44947735191637633
Recall: 0.7938461538461539
F1 Score: 0.5739710789766407
------------------------------------------
Number of Samples: 778
Accuracy: 0.41259640102827766
Precision (Weighted): 0.55095693548646
Recall (Weighted): 0.41259640102827766
F1 Score (Weighted): 0.37219727703577665
###################################################

Key: bert_5_200_C_gpt4
Path: ../models/bert_v1/5_200_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|103|350 | TP: 103, 22.74%; FN: 350; Total: 453
1|049|276 | TP: 276, 84.92%; FN: 49; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 103 & 350 \\
    \hline
    1 & 049 & 276 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.6776315789473685
Recall: 0.22737306843267108
F1 Score: 0.3404958677685951
------------------------------------------
Performance for category: 1
Precision: 0.44089456869009586
Recall: 0.8492307692307692
F1 Score: 0.580441640378549
------------------------------------------
Number of Samples: 778
Accuracy: 0.487146529562982
Precision (Weighted): 0.5787375836599473
Recall (Weighted): 0.487146529562982
F1 Score (Weighted): 0.4407302843473034
###################################################

Key: xgb_5_200_C_gpt4
Path: ../models/xgb_v1/5_200_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|046|012|233|162 | TP: 233, 51.43%; FN: 220; Total: 453
3|026|007|124|168 | TP: 168, 51.69%; FN: 157; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 046 & 012 & 233 & 162 \\
    \hline
    3 & 026 & 007 & 124 & 168 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6526610644257703
Recall: 0.5143487858719646
F1 Score: 0.5753086419753085
------------------------------------------
Performance for category: 3
Precision: 0.509090909090909
Recall: 0.5169230769230769
F1 Score: 0.5129770992366413
------------------------------------------
Number of Samples: 778
Accuracy: 0.5154241645244216
Precision (Weighted): 0.5926863851406419
Recall (Weighted): 0.5154241645244216
F1 Score (Weighted): 0.54927040111404
###################################################

Key: bert_5_200_D_gpt4
Path: ../models/bert_v1/5_200_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|001|010|442 | TP: 10, 2.21%; FN: 443; Total: 453
2|000|002|323 | TP: 323, 99.38%; FN: 2; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 001 & 010 & 442 \\
    \hline
    2 & 000 & 002 & 323 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.8333333333333334
Recall: 0.02207505518763797
F1 Score: 0.043010752688172046
------------------------------------------
Performance for category: 2
Precision: 0.4222222222222222
Recall: 0.9938461538461538
F1 Score: 0.5926605504587156
------------------------------------------
Number of Samples: 778
Accuracy: 0.42802056555269924
Precision (Weighted): 0.661596686660954
Recall (Weighted): 0.42802056555269924
F1 Score (Weighted): 0.27262024404476154
###################################################

Key: xgb_5_200_D_gpt4
Path: ../models/xgb_v1/5_200_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|043|013|113|284 | TP: 113, 24.94%; FN: 340; Total: 453
3|023|002|050|250 | TP: 250, 76.92%; FN: 75; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 043 & 013 & 113 & 284 \\
    \hline
    3 & 023 & 002 & 050 & 250 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6932515337423313
Recall: 0.24944812362030905
F1 Score: 0.36688311688311687
------------------------------------------
Performance for category: 3
Precision: 0.4681647940074906
Recall: 0.7692307692307693
F1 Score: 0.5820721769499417
------------------------------------------
Number of Samples: 778
Accuracy: 0.4665809768637532
Precision (Weighted): 0.5992242967065687
Recall (Weighted): 0.4665809768637532
F1 Score (Weighted): 0.45677571909612213
###################################################

Key: bert_5_200_E_gpt4
Path: ../models/bert_v1/5_200_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|004|009|440 | TP: 9, 1.99%; FN: 444; Total: 453
2|001|001|323 | TP: 323, 99.38%; FN: 2; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 004 & 009 & 440 \\
    \hline
    2 & 001 & 001 & 323 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.9
Recall: 0.019867549668874173
F1 Score: 0.038876889848812095
------------------------------------------
Performance for category: 2
Precision: 0.4233289646133683
Recall: 0.9938461538461538
F1 Score: 0.59375
------------------------------------------
Number of Samples: 778
Accuracy: 0.4267352185089974
Precision (Weighted): 0.7008764955004431
Recall (Weighted): 0.4267352185089974
F1 Score (Weighted): 0.2706683561716091
###################################################

Key: xgb_5_200_E_gpt4
Path: ../models/xgb_v1/5_200_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|043|006|063|341 | TP: 63, 13.91%; FN: 390; Total: 453
3|022|004|024|275 | TP: 275, 84.62%; FN: 50; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 043 & 006 & 063 & 341 \\
    \hline
    3 & 022 & 004 & 024 & 275 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.7241379310344828
Recall: 0.1390728476821192
F1 Score: 0.23333333333333334
------------------------------------------
Performance for category: 3
Precision: 0.44642857142857145
Recall: 0.8461538461538461
F1 Score: 0.5844845908607863
------------------------------------------
Number of Samples: 778
Accuracy: 0.43444730077120824
Precision (Weighted): 0.6081282371117049
Recall (Weighted): 0.43444730077120824
F1 Score (Weighted): 0.3800224833287346
###################################################

Key: bert_5_200_F_gpt4
Path: ../models/bert_v1/5_200_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|001|012|440 | TP: 12, 2.65%; FN: 441; Total: 453
2|000|003|322 | TP: 322, 99.08%; FN: 3; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 001 & 012 & 440 \\
    \hline
    2 & 000 & 003 & 322 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.8
Recall: 0.026490066225165563
F1 Score: 0.05128205128205128
------------------------------------------
Performance for category: 2
Precision: 0.4225721784776903
Recall: 0.9907692307692307
F1 Score: 0.5924563017479301
------------------------------------------
Number of Samples: 778
Accuracy: 0.42930591259640105
Precision (Weighted): 0.6423341362535339
Recall (Weighted): 0.42930591259640105
F1 Score (Weighted): 0.27735098624530397
###################################################

Key: xgb_5_200_F_gpt4
Path: ../models/xgb_v1/5_200_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|047|033|095|278 | TP: 95, 20.97%; FN: 358; Total: 453
3|019|014|047|245 | TP: 245, 75.38%; FN: 80; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 047 & 033 & 095 & 278 \\
    \hline
    3 & 019 & 014 & 047 & 245 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6690140845070423
Recall: 0.2097130242825607
F1 Score: 0.31932773109243695
------------------------------------------
Performance for category: 3
Precision: 0.4684512428298279
Recall: 0.7538461538461538
F1 Score: 0.5778301886792452
------------------------------------------
Number of Samples: 778
Accuracy: 0.4370179948586118
Precision (Weighted): 0.5852314064285143
Recall (Weighted): 0.4370179948586118
F1 Score (Weighted): 0.4273139762283144
###################################################

Key: bert_5_400_A_gpt4
Path: ../models/bert_v1/5_400_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|033|001|419 | TP: 1, 0.22%; FN: 452; Total: 453
2|016|001|308 | TP: 308, 94.77%; FN: 17; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 033 & 001 & 419 \\
    \hline
    2 & 016 & 001 & 308 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.5
Recall: 0.002207505518763797
F1 Score: 0.004395604395604396
------------------------------------------
Performance for category: 2
Precision: 0.4236588720770289
Recall: 0.9476923076923077
F1 Score: 0.5855513307984792
------------------------------------------
Number of Samples: 778
Accuracy: 0.397172236503856
Precision (Weighted): 0.4681094259961881
Recall (Weighted): 0.397172236503856
F1 Score (Weighted): 0.24716631272585415
###################################################

Key: xgb_5_400_A_gpt4
Path: ../models/xgb_v1/5_400_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|041|013|103|296 | TP: 103, 22.74%; FN: 350; Total: 453
3|020|004|044|257 | TP: 257, 79.08%; FN: 68; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 041 & 013 & 103 & 296 \\
    \hline
    3 & 020 & 004 & 044 & 257 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.7006802721088435
Recall: 0.22737306843267108
F1 Score: 0.3433333333333333
------------------------------------------
Performance for category: 3
Precision: 0.46473779385171793
Recall: 0.7907692307692308
F1 Score: 0.5854214123006833
------------------------------------------
Number of Samples: 778
Accuracy: 0.46272493573264784
Precision (Weighted): 0.6021181828626151
Recall (Weighted): 0.46272493573264784
F1 Score (Weighted): 0.44446267223357594
###################################################

Key: bert_5_400_B_gpt4
Path: ../models/bert_v1/5_400_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|054|005|394 | TP: 5, 1.1%; FN: 448; Total: 453
2|026|001|298 | TP: 298, 91.69%; FN: 27; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 054 & 005 & 394 \\
    \hline
    2 & 026 & 001 & 298 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.8333333333333334
Recall: 0.011037527593818985
F1 Score: 0.021786492374727674
------------------------------------------
Performance for category: 2
Precision: 0.430635838150289
Recall: 0.916923076923077
F1 Score: 0.5860373647984267
------------------------------------------
Number of Samples: 778
Accuracy: 0.38946015424164526
Precision (Weighted): 0.6651113719779485
Recall (Weighted): 0.38946015424164526
F1 Score (Weighted): 0.2574954043769156
###################################################

Key: xgb_5_400_B_gpt4
Path: ../models/xgb_v1/5_400_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|045|014|108|286 | TP: 108, 23.84%; FN: 345; Total: 453
3|025|003|078|219 | TP: 219, 67.38%; FN: 106; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 045 & 014 & 108 & 286 \\
    \hline
    3 & 025 & 003 & 078 & 219 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.5806451612903226
Recall: 0.23841059602649006
F1 Score: 0.3380281690140845
------------------------------------------
Performance for category: 3
Precision: 0.43366336633663366
Recall: 0.6738461538461539
F1 Score: 0.5277108433734939
------------------------------------------
Number of Samples: 778
Accuracy: 0.4203084832904884
Precision (Weighted): 0.5192453112132674
Recall (Weighted): 0.4203084832904884
F1 Score (Weighted): 0.4172657900511129
###################################################

Key: bert_5_400_C_gpt4
Path: ../models/bert_v1/5_400_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|025|000|428 | TP: 0, 0.0%; FN: 453; Total: 453
2|005|000|320 | TP: 320, 98.46%; FN: 5; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 025 & 000 & 428 \\
    \hline
    2 & 005 & 000 & 320 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.42780748663101603
Recall: 0.9846153846153847
F1 Score: 0.5964585274930103
------------------------------------------
Number of Samples: 778
Accuracy: 0.41131105398457585
Precision (Weighted): 0.1787113536697689
Recall (Weighted): 0.41131105398457585
F1 Score (Weighted): 0.24916326662625754
###################################################

Key: xgb_5_400_C_gpt4
Path: ../models/xgb_v1/5_400_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|056|015|162|220 | TP: 162, 35.76%; FN: 291; Total: 453
3|025|007|076|217 | TP: 217, 66.77%; FN: 108; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 056 & 015 & 162 & 220 \\
    \hline
    3 & 025 & 007 & 076 & 217 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.680672268907563
Recall: 0.3576158940397351
F1 Score: 0.4688856729377713
------------------------------------------
Performance for category: 3
Precision: 0.4965675057208238
Recall: 0.6676923076923077
F1 Score: 0.5695538057742783
------------------------------------------
Number of Samples: 778
Accuracy: 0.487146529562982
Precision (Weighted): 0.6037647521521771
Recall (Weighted): 0.487146529562982
F1 Score (Weighted): 0.5109385561920963
###################################################

Key: bert_5_400_D_gpt4
Path: ../models/bert_v1/5_400_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|019|040|394 | TP: 40, 8.83%; FN: 413; Total: 453
2|007|019|299 | TP: 299, 92.0%; FN: 26; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 019 & 040 & 394 \\
    \hline
    2 & 007 & 019 & 299 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.6779661016949152
Recall: 0.08830022075055188
F1 Score: 0.15625000000000003
------------------------------------------
Performance for category: 2
Precision: 0.4314574314574315
Recall: 0.92
F1 Score: 0.587426326129666
------------------------------------------
Number of Samples: 778
Accuracy: 0.43573264781491
Precision (Weighted): 0.5749901147705164
Recall (Weighted): 0.43573264781491
F1 Score (Weighted): 0.336368645234115
###################################################

Key: xgb_5_400_D_gpt4
Path: ../models/xgb_v1/5_400_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|036|034|158|225 | TP: 158, 34.88%; FN: 295; Total: 453
3|022|011|088|204 | TP: 204, 62.77%; FN: 121; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 036 & 034 & 158 & 225 \\
    \hline
    3 & 022 & 011 & 088 & 204 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6422764227642277
Recall: 0.3487858719646799
F1 Score: 0.4520743919885551
------------------------------------------
Performance for category: 3
Precision: 0.4755244755244755
Recall: 0.6276923076923077
F1 Score: 0.5411140583554376
------------------------------------------
Number of Samples: 778
Accuracy: 0.4652956298200514
Precision (Weighted): 0.5726178329789842
Recall (Weighted): 0.4652956298200514
F1 Score (Weighted): 0.48926962536803686
###################################################

Key: bert_5_400_E_gpt4
Path: ../models/bert_v1/5_400_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|006|023|424 | TP: 23, 5.08%; FN: 430; Total: 453
2|002|012|311 | TP: 311, 95.69%; FN: 14; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 006 & 023 & 424 \\
    \hline
    2 & 002 & 012 & 311 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.6571428571428571
Recall: 0.05077262693156733
F1 Score: 0.0942622950819672
------------------------------------------
Performance for category: 2
Precision: 0.4231292517006803
Recall: 0.9569230769230769
F1 Score: 0.5867924528301887
------------------------------------------
Number of Samples: 778
Accuracy: 0.42930591259640105
Precision (Weighted): 0.5593865309619992
Recall (Weighted): 0.42930591259640105
F1 Score (Weighted): 0.30001075429555585
###################################################

Key: xgb_5_400_E_gpt4
Path: ../models/xgb_v1/5_400_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|041|004|150|258 | TP: 150, 33.11%; FN: 303; Total: 453
3|019|004|068|234 | TP: 234, 72.0%; FN: 91; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 041 & 004 & 150 & 258 \\
    \hline
    3 & 019 & 004 & 068 & 234 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6880733944954128
Recall: 0.33112582781456956
F1 Score: 0.44709388971684055
------------------------------------------
Performance for category: 3
Precision: 0.47560975609756095
Recall: 0.72
F1 Score: 0.5728274173806609
------------------------------------------
Number of Samples: 778
Accuracy: 0.493573264781491
Precision (Weighted): 0.5993193039050505
Recall (Weighted): 0.493573264781491
F1 Score (Weighted): 0.49961753559182975
###################################################

Key: bert_5_400_F_gpt4
Path: ../models/bert_v1/5_400_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|027|013|413 | TP: 13, 2.87%; FN: 440; Total: 453
2|014|008|303 | TP: 303, 93.23%; FN: 22; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 027 & 013 & 413 \\
    \hline
    2 & 014 & 008 & 303 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.6190476190476191
Recall: 0.02869757174392936
F1 Score: 0.05485232067510548
------------------------------------------
Performance for category: 2
Precision: 0.4231843575418994
Recall: 0.9323076923076923
F1 Score: 0.5821325648414986
------------------------------------------
Number of Samples: 778
Accuracy: 0.40616966580976865
Precision (Weighted): 0.5372281332001141
Recall (Weighted): 0.40616966580976865
F1 Score (Weighted): 0.2751172041636373
###################################################

Key: xgb_5_400_F_gpt4
Path: ../models/xgb_v1/5_400_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|043|007|194|209 | TP: 194, 42.83%; FN: 259; Total: 453
3|025|007|100|193 | TP: 193, 59.38%; FN: 132; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 043 & 007 & 194 & 209 \\
    \hline
    3 & 025 & 007 & 100 & 193 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6598639455782312
Recall: 0.4282560706401766
F1 Score: 0.5194109772423026
------------------------------------------
Performance for category: 3
Precision: 0.48009950248756217
Recall: 0.5938461538461538
F1 Score: 0.530949105914718
------------------------------------------
Number of Samples: 778
Accuracy: 0.4974293059125964
Precision (Weighted): 0.5847695445442114
Recall (Weighted): 0.4974293059125964
F1 Score (Weighted): 0.5242308896054582
###################################################

Key: bert_5_800_A_gpt4
Path: ../models/bert_v1/5_800_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|030|208|215 | TP: 208, 45.92%; FN: 245; Total: 453
2|014|106|205 | TP: 205, 63.08%; FN: 120; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 030 & 208 & 215 \\
    \hline
    2 & 014 & 106 & 205 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.6624203821656051
Recall: 0.45916114790286977
F1 Score: 0.5423728813559322
------------------------------------------
Performance for category: 2
Precision: 0.4880952380952381
Recall: 0.6307692307692307
F1 Score: 0.5503355704697985
------------------------------------------
Number of Samples: 778
Accuracy: 0.5308483290488432
Precision (Weighted): 0.5895981818791407
Recall (Weighted): 0.5308483290488432
F1 Score (Weighted): 0.5456991975024702
###################################################

Key: xgb_5_800_A_gpt4
Path: ../models/xgb_v1/5_800_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|046|020|124|263 | TP: 124, 27.37%; FN: 329; Total: 453
3|022|006|049|248 | TP: 248, 76.31%; FN: 77; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 046 & 020 & 124 & 263 \\
    \hline
    3 & 022 & 006 & 049 & 248 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.7167630057803468
Recall: 0.2737306843267108
F1 Score: 0.3961661341853035
------------------------------------------
Performance for category: 3
Precision: 0.48532289628180036
Recall: 0.7630769230769231
F1 Score: 0.5933014354066986
------------------------------------------
Number of Samples: 778
Accuracy: 0.4781491002570694
Precision (Weighted): 0.6200817261055042
Recall (Weighted): 0.4781491002570694
F1 Score (Weighted): 0.47851699909141326
###################################################

Key: bert_5_800_B_gpt4
Path: ../models/bert_v1/5_800_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|025|075|353 | TP: 75, 16.56%; FN: 378; Total: 453
2|012|032|281 | TP: 281, 86.46%; FN: 44; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 025 & 075 & 353 \\
    \hline
    2 & 012 & 032 & 281 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.7009345794392523
Recall: 0.16556291390728478
F1 Score: 0.2678571428571429
------------------------------------------
Performance for category: 2
Precision: 0.443217665615142
Recall: 0.8646153846153846
F1 Score: 0.5860271115745569
------------------------------------------
Number of Samples: 778
Accuracy: 0.45758354755784064
Precision (Weighted): 0.5932764856181265
Recall (Weighted): 0.45758354755784064
F1 Score (Weighted): 0.4007687621799701
###################################################

Key: xgb_5_800_B_gpt4
Path: ../models/xgb_v1/5_800_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|043|008|148|254 | TP: 148, 32.67%; FN: 305; Total: 453
3|023|005|054|243 | TP: 243, 74.77%; FN: 82; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 043 & 008 & 148 & 254 \\
    \hline
    3 & 023 & 005 & 054 & 243 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.7326732673267327
Recall: 0.32671081677704195
F1 Score: 0.4519083969465648
------------------------------------------
Performance for category: 3
Precision: 0.48893360160965793
Recall: 0.7476923076923077
F1 Score: 0.5912408759124087
------------------------------------------
Number of Samples: 778
Accuracy: 0.5025706940874036
Precision (Weighted): 0.6308539982289829
Recall (Weighted): 0.5025706940874036
F1 Score (Weighted): 0.5101128386739417
###################################################

Key: bert_5_800_C_gpt4
Path: ../models/bert_v1/5_800_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|028|173|252 | TP: 173, 38.19%; FN: 280; Total: 453
2|015|077|233 | TP: 233, 71.69%; FN: 92; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 028 & 173 & 252 \\
    \hline
    2 & 015 & 077 & 233 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.692
Recall: 0.3818984547461369
F1 Score: 0.492176386913229
------------------------------------------
Performance for category: 2
Precision: 0.48041237113402063
Recall: 0.7169230769230769
F1 Score: 0.5753086419753087
------------------------------------------
Number of Samples: 778
Accuracy: 0.5218508997429306
Precision (Weighted): 0.603611851694803
Recall (Weighted): 0.5218508997429306
F1 Score (Weighted): 0.5269038713543291
###################################################

Key: xgb_5_800_C_gpt4
Path: ../models/xgb_v1/5_800_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|036|019|169|229 | TP: 169, 37.31%; FN: 284; Total: 453
3|018|015|086|206 | TP: 206, 63.38%; FN: 119; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 036 & 019 & 169 & 229 \\
    \hline
    3 & 018 & 015 & 086 & 206 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6627450980392157
Recall: 0.3730684326710817
F1 Score: 0.47740112994350287
------------------------------------------
Performance for category: 3
Precision: 0.4735632183908046
Recall: 0.6338461538461538
F1 Score: 0.5421052631578948
------------------------------------------
Number of Samples: 778
Accuracy: 0.4820051413881748
Precision (Weighted): 0.5837166778776044
Recall (Weighted): 0.4820051413881748
F1 Score (Weighted): 0.5044304915047849
###################################################

Key: bert_5_800_D_gpt4
Path: ../models/bert_v1/5_800_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|063|086|304 | TP: 86, 18.98%; FN: 367; Total: 453
2|031|037|257 | TP: 257, 79.08%; FN: 68; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 063 & 086 & 304 \\
    \hline
    2 & 031 & 037 & 257 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.6991869918699187
Recall: 0.18984547461368653
F1 Score: 0.2986111111111111
------------------------------------------
Performance for category: 2
Precision: 0.45811051693404636
Recall: 0.7907692307692308
F1 Score: 0.5801354401805869
------------------------------------------
Number of Samples: 778
Accuracy: 0.44087403598971725
Precision (Weighted): 0.5984802382013344
Recall (Weighted): 0.44087403598971725
F1 Score (Weighted): 0.4162144619434758
###################################################

Key: xgb_5_800_D_gpt4
Path: ../models/xgb_v1/5_800_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|031|032|133|257 | TP: 133, 29.36%; FN: 320; Total: 453
3|017|021|055|232 | TP: 232, 71.38%; FN: 93; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 031 & 032 & 133 & 257 \\
    \hline
    3 & 017 & 021 & 055 & 232 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.7074468085106383
Recall: 0.293598233995585
F1 Score: 0.41497659906396256
------------------------------------------
Performance for category: 3
Precision: 0.47443762781186094
Recall: 0.7138461538461538
F1 Score: 0.57002457002457
------------------------------------------
Number of Samples: 778
Accuracy: 0.4691516709511568
Precision (Weighted): 0.610110068501509
Recall (Weighted): 0.4691516709511568
F1 Score (Weighted): 0.4797459956734708
###################################################

Key: bert_5_800_E_gpt4
Path: ../models/bert_v1/5_800_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|021|022|410 | TP: 22, 4.86%; FN: 431; Total: 453
2|005|016|304 | TP: 304, 93.54%; FN: 21; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 021 & 022 & 410 \\
    \hline
    2 & 005 & 016 & 304 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.5789473684210527
Recall: 0.04856512141280353
F1 Score: 0.08961303462321792
------------------------------------------
Performance for category: 2
Precision: 0.4257703081232493
Recall: 0.9353846153846154
F1 Score: 0.5851780558229067
------------------------------------------
Number of Samples: 778
Accuracy: 0.4190231362467866
Precision (Weighted): 0.5149595218956207
Recall (Weighted): 0.4190231362467866
F1 Score (Weighted): 0.2966292709855558
###################################################

Key: xgb_5_800_E_gpt4
Path: ../models/xgb_v1/5_800_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|038|032|111|272 | TP: 111, 24.5%; FN: 342; Total: 453
3|017|018|053|237 | TP: 237, 72.92%; FN: 88; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 038 & 032 & 111 & 272 \\
    \hline
    3 & 017 & 018 & 053 & 237 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.676829268292683
Recall: 0.24503311258278146
F1 Score: 0.35980551053484605
------------------------------------------
Performance for category: 3
Precision: 0.4656188605108055
Recall: 0.7292307692307692
F1 Score: 0.5683453237410071
------------------------------------------
Number of Samples: 778
Accuracy: 0.4473007712082262
Precision (Weighted): 0.5885986994891994
Recall (Weighted): 0.4473007712082262
F1 Score (Weighted): 0.4469204710644121
###################################################

Key: bert_5_800_F_gpt4
Path: ../models/bert_v1/5_800_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|044|067|342 | TP: 67, 14.79%; FN: 386; Total: 453
2|022|021|282 | TP: 282, 86.77%; FN: 43; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 044 & 067 & 342 \\
    \hline
    2 & 022 & 021 & 282 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.7613636363636364
Recall: 0.1479028697571744
F1 Score: 0.2476894639556377
------------------------------------------
Performance for category: 2
Precision: 0.4519230769230769
Recall: 0.8676923076923077
F1 Score: 0.5943097997892518
------------------------------------------
Number of Samples: 778
Accuracy: 0.448586118251928
Precision (Weighted): 0.6320986211731713
Recall (Weighted): 0.448586118251928
F1 Score (Weighted): 0.39248587673960245
###################################################

Key: xgb_5_800_F_gpt4
Path: ../models/xgb_v1/5_800_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|050|025|122|256 | TP: 122, 26.93%; FN: 331; Total: 453
3|024|012|049|240 | TP: 240, 73.85%; FN: 85; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 050 & 025 & 122 & 256 \\
    \hline
    3 & 024 & 012 & 049 & 240 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.7134502923976608
Recall: 0.2693156732891832
F1 Score: 0.3910256410256411
------------------------------------------
Performance for category: 3
Precision: 0.4838709677419355
Recall: 0.7384615384615385
F1 Score: 0.584652862362972
------------------------------------------
Number of Samples: 778
Accuracy: 0.4652956298200514
Precision (Weighted): 0.6175463328692408
Recall (Weighted): 0.4652956298200514
F1 Score (Weighted): 0.47191104839663406
###################################################

Key: bert_5_1600_A_gpt4
Path: ../models/bert_v1/5_1600_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|038|066|349 | TP: 66, 14.57%; FN: 387; Total: 453
2|027|020|278 | TP: 278, 85.54%; FN: 47; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 038 & 066 & 349 \\
    \hline
    2 & 027 & 020 & 278 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.7674418604651163
Recall: 0.1456953642384106
F1 Score: 0.24489795918367346
------------------------------------------
Performance for category: 2
Precision: 0.4433811802232855
Recall: 0.8553846153846154
F1 Score: 0.5840336134453782
------------------------------------------
Number of Samples: 778
Accuracy: 0.442159383033419
Precision (Weighted): 0.6320694683332462
Recall (Weighted): 0.442159383033419
F1 Score (Weighted): 0.38656773763489977
###################################################

Key: xgb_5_1600_A_gpt4
Path: ../models/xgb_v1/5_1600_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|042|012|118|281 | TP: 118, 26.05%; FN: 335; Total: 453
3|022|008|051|244 | TP: 244, 75.08%; FN: 81; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 042 & 012 & 118 & 281 \\
    \hline
    3 & 022 & 008 & 051 & 244 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.6982248520710059
Recall: 0.26048565121412803
F1 Score: 0.3794212218649518
------------------------------------------
Performance for category: 3
Precision: 0.46476190476190476
Recall: 0.7507692307692307
F1 Score: 0.5741176470588235
------------------------------------------
Number of Samples: 778
Accuracy: 0.4652956298200514
Precision (Weighted): 0.6006985566012657
Recall (Weighted): 0.4652956298200514
F1 Score (Weighted): 0.4607532760911836
###################################################

Key: bert_5_3200_A_gpt4
Path: ../models/bert_v1/5_3200_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|014|008|064|367 | TP: 64, 14.13%; FN: 389; Total: 453
3|005|008|025|287 | TP: 287, 88.31%; FN: 38; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 014 & 008 & 064 & 367 \\
    \hline
    3 & 005 & 008 & 025 & 287 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.7191011235955056
Recall: 0.141280353200883
F1 Score: 0.23616236162361623
------------------------------------------
Performance for category: 3
Precision: 0.43883792048929665
Recall: 0.8830769230769231
F1 Score: 0.5863125638406538
------------------------------------------
Number of Samples: 778
Accuracy: 0.45115681233933164
Precision (Weighted): 0.6020245927349428
Recall (Weighted): 0.45115681233933164
F1 Score (Weighted): 0.3824333329867746
###################################################

Key: xgb_5_3200_A_gpt4
Path: ../models/xgb_v1/5_3200_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|047|018|147|241 | TP: 147, 32.45%; FN: 306; Total: 453
3|018|010|062|235 | TP: 235, 72.31%; FN: 90; Total: 325
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 047 & 018 & 147 & 241 \\
    \hline
    3 & 018 & 010 & 062 & 235 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.7033492822966507
Recall: 0.32450331125827814
F1 Score: 0.44410876132930505
------------------------------------------
Performance for category: 3
Precision: 0.49369747899159666
Recall: 0.7230769230769231
F1 Score: 0.5867665418227216
------------------------------------------
Number of Samples: 778
Accuracy: 0.4910025706940874
Precision (Weighted): 0.6157698014815575
Recall (Weighted): 0.4910025706940874
F1 Score (Weighted): 0.5037023071652438
###################################################

