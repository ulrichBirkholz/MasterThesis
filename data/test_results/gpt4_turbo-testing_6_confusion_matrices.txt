Key: bert_6_50_A_gpt4
Path: ../models/bert_v1/6_50_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|002|098|052|000 | TP: 52, 34.21%; FN: 100; Total: 152
3|005|327|314|000 | TP: 0, 0.0%; FN: 646; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 002 & 098 & 052 & 000 \\
    \hline
    3 & 005 & 327 & 314 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.14207650273224043
Recall: 0.34210526315789475
F1 Score: 0.20077220077220076
------------------------------------------
Performance for category: 3
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 798
Accuracy: 0.06516290726817042
Precision (Weighted): 0.027062190996617226
Recall (Weighted): 0.06516290726817042
F1 Score (Weighted): 0.03824232395660967
###################################################

Key: xgb_6_50_A_gpt4
Path: ../models/xgb_v1/6_50_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|022|003|127 | TP: 3, 1.97%; FN: 149; Total: 152
2|058|015|573 | TP: 573, 88.7%; FN: 73; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 022 & 003 & 127 \\
    \hline
    2 & 058 & 015 & 573 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.16666666666666666
Recall: 0.019736842105263157
F1 Score: 0.03529411764705882
------------------------------------------
Performance for category: 2
Precision: 0.8185714285714286
Recall: 0.8869969040247678
F1 Score: 0.8514115898959883
------------------------------------------
Number of Samples: 798
Accuracy: 0.7218045112781954
Precision (Weighted): 0.6943990929705216
Recall (Weighted): 0.7218045112781954
F1 Score (Weighted): 0.6959606428009542
###################################################

Key: bert_6_50_B_gpt4
Path: ../models/bert_v1/6_50_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|001|088|063|000 | TP: 63, 41.45%; FN: 89; Total: 152
3|001|283|362|000 | TP: 0, 0.0%; FN: 646; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 001 & 088 & 063 & 000 \\
    \hline
    3 & 001 & 283 & 362 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.14823529411764705
Recall: 0.4144736842105263
F1 Score: 0.21837088388214904
------------------------------------------
Performance for category: 3
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 798
Accuracy: 0.07894736842105263
Precision (Weighted): 0.02823529411764706
Recall (Weighted): 0.07894736842105263
F1 Score (Weighted): 0.04159445407279029
###################################################

Key: xgb_6_50_B_gpt4
Path: ../models/xgb_v1/6_50_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|007|000|145 | TP: 0, 0.0%; FN: 152; Total: 152
2|019|003|624 | TP: 624, 96.59%; FN: 22; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 007 & 000 & 145 \\
    \hline
    2 & 019 & 003 & 624 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.811443433029909
Recall: 0.9659442724458205
F1 Score: 0.8819787985865725
------------------------------------------
Number of Samples: 798
Accuracy: 0.7819548872180451
Precision (Weighted): 0.6568827791194501
Recall (Weighted): 0.7819548872180451
F1 Score (Weighted): 0.7139828369510348
###################################################

Key: bert_6_50_C_gpt4
Path: ../models/bert_v1/6_50_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|096|056|000 | TP: 56, 36.84%; FN: 96; Total: 152
2|324|322|000 | TP: 0, 0.0%; FN: 646; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 096 & 056 & 000 \\
    \hline
    2 & 324 & 322 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.14814814814814814
Recall: 0.3684210526315789
F1 Score: 0.2113207547169811
------------------------------------------
Performance for category: 2
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 798
Accuracy: 0.07017543859649122
Precision (Weighted): 0.028218694885361554
Recall (Weighted): 0.07017543859649122
F1 Score (Weighted): 0.04025157232704402
###################################################

Key: xgb_6_50_C_gpt4
Path: ../models/xgb_v1/6_50_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|024|007|052|069 | TP: 52, 34.21%; FN: 100; Total: 152
3|067|024|154|401 | TP: 401, 62.07%; FN: 245; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 024 & 007 & 052 & 069 \\
    \hline
    3 & 067 & 024 & 154 & 401 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.2524271844660194
Recall: 0.34210526315789475
F1 Score: 0.29050279329608936
------------------------------------------
Performance for category: 3
Precision: 0.8531914893617021
Recall: 0.6207430340557275
F1 Score: 0.7186379928315411
------------------------------------------
Number of Samples: 798
Accuracy: 0.5676691729323309
Precision (Weighted): 0.7387601931910958
Recall (Weighted): 0.5676691729323308
F1 Score (Weighted): 0.6370884310152646
###################################################

Key: bert_6_50_D_gpt4
Path: ../models/bert_v1/6_50_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|001|098|053|000 | TP: 53, 34.87%; FN: 99; Total: 152
3|002|323|321|000 | TP: 0, 0.0%; FN: 646; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 001 & 098 & 053 & 000 \\
    \hline
    3 & 002 & 323 & 321 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.14171122994652408
Recall: 0.34868421052631576
F1 Score: 0.20152091254752852
------------------------------------------
Performance for category: 3
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 798
Accuracy: 0.06641604010025062
Precision (Weighted): 0.02699261522790935
Recall (Weighted): 0.06641604010025062
F1 Score (Weighted): 0.038384935723338766
###################################################

Key: xgb_6_50_D_gpt4
Path: ../models/xgb_v1/6_50_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|048|003|101 | TP: 3, 1.97%; FN: 149; Total: 152
2|172|022|452 | TP: 452, 69.97%; FN: 194; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 048 & 003 & 101 \\
    \hline
    2 & 172 & 022 & 452 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.12
Recall: 0.019736842105263157
F1 Score: 0.033898305084745756
------------------------------------------
Performance for category: 2
Precision: 0.8173598553345389
Recall: 0.6996904024767802
F1 Score: 0.7539616346955796
------------------------------------------
Number of Samples: 798
Accuracy: 0.5701754385964912
Precision (Weighted): 0.6845294066993886
Recall (Weighted): 0.5701754385964912
F1 Score (Weighted): 0.6168067147697065
###################################################

Key: bert_6_50_E_gpt4
Path: ../models/bert_v1/6_50_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|001|093|058|000 | TP: 58, 38.16%; FN: 94; Total: 152
3|001|306|339|000 | TP: 0, 0.0%; FN: 646; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 001 & 093 & 058 & 000 \\
    \hline
    3 & 001 & 306 & 339 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.14609571788413098
Recall: 0.3815789473684211
F1 Score: 0.21129326047358835
------------------------------------------
Performance for category: 3
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 798
Accuracy: 0.07268170426065163
Precision (Weighted): 0.027827755787453518
Recall (Weighted): 0.07268170426065163
F1 Score (Weighted): 0.040246335328302546
###################################################

Key: xgb_6_50_E_gpt4
Path: ../models/xgb_v1/6_50_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|068|000|013|071 | TP: 13, 8.55%; FN: 139; Total: 152
3|260|001|057|328 | TP: 328, 50.77%; FN: 318; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 068 & 000 & 013 & 071 \\
    \hline
    3 & 260 & 001 & 057 & 328 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.18571428571428572
Recall: 0.08552631578947369
F1 Score: 0.11711711711711711
------------------------------------------
Performance for category: 3
Precision: 0.8220551378446115
Recall: 0.5077399380804953
F1 Score: 0.6277511961722487
------------------------------------------
Number of Samples: 798
Accuracy: 0.4273182957393484
Precision (Weighted): 0.7008473564864541
Recall (Weighted): 0.4273182957393484
F1 Score (Weighted): 0.5304875620665094
###################################################

Key: bert_6_50_F_gpt4
Path: ../models/bert_v1/6_50_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|000|098|054|000 | TP: 54, 35.53%; FN: 98; Total: 152
3|001|325|320|000 | TP: 0, 0.0%; FN: 646; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 000 & 098 & 054 & 000 \\
    \hline
    3 & 001 & 325 & 320 & 000 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.1443850267379679
Recall: 0.35526315789473684
F1 Score: 0.2053231939163498
------------------------------------------
Performance for category: 3
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Number of Samples: 798
Accuracy: 0.06766917293233082
Precision (Weighted): 0.027501909854851028
Recall (Weighted): 0.06766917293233082
F1 Score (Weighted): 0.03910917979359044
###################################################

Key: xgb_6_50_F_gpt4
Path: ../models/xgb_v1/6_50_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|024|001|025|102 | TP: 25, 16.45%; FN: 127; Total: 152
3|072|005|076|493 | TP: 493, 76.32%; FN: 153; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 024 & 001 & 025 & 102 \\
    \hline
    3 & 072 & 005 & 076 & 493 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.24752475247524752
Recall: 0.16447368421052633
F1 Score: 0.19762845849802374
------------------------------------------
Performance for category: 3
Precision: 0.8285714285714286
Recall: 0.7631578947368421
F1 Score: 0.7945205479452055
------------------------------------------
Number of Samples: 798
Accuracy: 0.6491228070175439
Precision (Weighted): 0.717895871219775
Recall (Weighted): 0.6491228070175439
F1 Score (Weighted): 0.6808268166219329
###################################################

Key: bert_6_100_A_gpt4
Path: ../models/bert_v1/6_100_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|002|086|064|000 | TP: 64, 42.11%; FN: 88; Total: 152
3|023|223|386|014 | TP: 14, 2.17%; FN: 632; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 002 & 086 & 064 & 000 \\
    \hline
    3 & 023 & 223 & 386 & 014 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.14222222222222222
Recall: 0.42105263157894735
F1 Score: 0.21262458471760795
------------------------------------------
Performance for category: 3
Precision: 1.0
Recall: 0.021671826625386997
F1 Score: 0.04242424242424243
------------------------------------------
Number of Samples: 798
Accuracy: 0.09774436090225563
Precision (Weighted): 0.8366137566137566
Recall (Weighted): 0.09774436090225563
F1 Score (Weighted): 0.07484335524202633
###################################################

Key: xgb_6_100_A_gpt4
Path: ../models/xgb_v1/6_100_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|038|004|008|102 | TP: 8, 5.26%; FN: 144; Total: 152
3|118|008|008|512 | TP: 512, 79.26%; FN: 134; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 038 & 004 & 008 & 102 \\
    \hline
    3 & 118 & 008 & 008 & 512 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.5
Recall: 0.05263157894736842
F1 Score: 0.09523809523809525
------------------------------------------
Performance for category: 3
Precision: 0.8338762214983714
Recall: 0.7925696594427245
F1 Score: 0.8126984126984127
------------------------------------------
Number of Samples: 798
Accuracy: 0.6516290726817042
Precision (Weighted): 0.7702807507367768
Recall (Weighted): 0.6516290726817042
F1 Score (Weighted): 0.6760393046107331
###################################################

Key: bert_6_100_B_gpt4
Path: ../models/bert_v1/6_100_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|114|033|005 | TP: 33, 21.71%; FN: 119; Total: 152
2|407|192|047 | TP: 47, 7.28%; FN: 599; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 114 & 033 & 005 \\
    \hline
    2 & 407 & 192 & 047 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.14666666666666667
Recall: 0.21710526315789475
F1 Score: 0.17506631299734748
------------------------------------------
Performance for category: 2
Precision: 0.9038461538461539
Recall: 0.07275541795665634
F1 Score: 0.13467048710601717
------------------------------------------
Number of Samples: 798
Accuracy: 0.10025062656641603
Precision (Weighted): 0.7596214896214896
Recall (Weighted): 0.10025062656641603
F1 Score (Weighted): 0.14236493013293725
###################################################

Key: xgb_6_100_B_gpt4
Path: ../models/xgb_v1/6_100_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|026|000|013|113 | TP: 13, 8.55%; FN: 139; Total: 152
3|051|001|055|539 | TP: 539, 83.44%; FN: 107; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 026 & 000 & 013 & 113 \\
    \hline
    3 & 051 & 001 & 055 & 539 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.19117647058823528
Recall: 0.08552631578947369
F1 Score: 0.11818181818181818
------------------------------------------
Performance for category: 3
Precision: 0.8266871165644172
Recall: 0.8343653250773994
F1 Score: 0.8305084745762711
------------------------------------------
Number of Samples: 798
Accuracy: 0.6917293233082706
Precision (Weighted): 0.7056374697118111
Recall (Weighted): 0.6917293233082706
F1 Score (Weighted): 0.6948272066916135
###################################################

Key: bert_6_100_C_gpt4
Path: ../models/bert_v1/6_100_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|002|055|095|000 | TP: 95, 62.5%; FN: 57; Total: 152
3|001|141|479|025 | TP: 25, 3.87%; FN: 621; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 002 & 055 & 095 & 000 \\
    \hline
    3 & 001 & 141 & 479 & 025 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.16550522648083624
Recall: 0.625
F1 Score: 0.26170798898071623
------------------------------------------
Performance for category: 3
Precision: 1.0
Recall: 0.03869969040247678
F1 Score: 0.07451564828614009
------------------------------------------
Number of Samples: 798
Accuracy: 0.15037593984962405
Precision (Weighted): 0.8410486145677784
Recall (Weighted): 0.15037593984962405
F1 Score (Weighted): 0.11017133222796412
###################################################

Key: xgb_6_100_C_gpt4
Path: ../models/xgb_v1/6_100_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|045|006|031|070 | TP: 31, 20.39%; FN: 121; Total: 152
3|133|021|079|413 | TP: 413, 63.93%; FN: 233; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 045 & 006 & 031 & 070 \\
    \hline
    3 & 133 & 021 & 079 & 413 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.2818181818181818
Recall: 0.20394736842105263
F1 Score: 0.2366412213740458
------------------------------------------
Performance for category: 3
Precision: 0.855072463768116
Recall: 0.6393188854489165
F1 Score: 0.7316209034543845
------------------------------------------
Number of Samples: 798
Accuracy: 0.556390977443609
Precision (Weighted): 0.7458811719681285
Recall (Weighted): 0.5563909774436091
F1 Score (Weighted): 0.6373390592486057
###################################################

Key: bert_6_100_D_gpt4
Path: ../models/bert_v1/6_100_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|114|031|007 | TP: 31, 20.39%; FN: 121; Total: 152
2|408|150|088 | TP: 88, 13.62%; FN: 558; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 114 & 031 & 007 \\
    \hline
    2 & 408 & 150 & 088 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.1712707182320442
Recall: 0.20394736842105263
F1 Score: 0.18618618618618618
------------------------------------------
Performance for category: 2
Precision: 0.9263157894736842
Recall: 0.13622291021671826
F1 Score: 0.23751686909581646
------------------------------------------
Number of Samples: 798
Accuracy: 0.14912280701754385
Precision (Weighted): 0.7824976806657526
Recall (Weighted): 0.14912280701754385
F1 Score (Weighted): 0.2277395961606488
###################################################

Key: xgb_6_100_D_gpt4
Path: ../models/xgb_v1/6_100_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|042|005|009|096 | TP: 9, 5.92%; FN: 143; Total: 152
3|123|008|023|492 | TP: 492, 76.16%; FN: 154; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 042 & 005 & 009 & 096 \\
    \hline
    3 & 123 & 008 & 023 & 492 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.28125
Recall: 0.05921052631578947
F1 Score: 0.09782608695652172
------------------------------------------
Performance for category: 3
Precision: 0.8367346938775511
Recall: 0.7616099071207431
F1 Score: 0.7974068071312804
------------------------------------------
Number of Samples: 798
Accuracy: 0.6278195488721805
Precision (Weighted): 0.7309280855199223
Recall (Weighted): 0.6278195488721805
F1 Score (Weighted): 0.6641533366218025
###################################################

Key: bert_6_100_E_gpt4
Path: ../models/bert_v1/6_100_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|004|102|046|000 | TP: 46, 30.26%; FN: 106; Total: 152
3|033|338|265|010 | TP: 10, 1.55%; FN: 636; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 004 & 102 & 046 & 000 \\
    \hline
    3 & 033 & 338 & 265 & 010 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.14790996784565916
Recall: 0.3026315789473684
F1 Score: 0.19870410367170627
------------------------------------------
Performance for category: 3
Precision: 1.0
Recall: 0.015479876160990712
F1 Score: 0.030487804878048783
------------------------------------------
Number of Samples: 798
Accuracy: 0.07017543859649122
Precision (Weighted): 0.8376971367325065
Recall (Weighted): 0.07017543859649122
F1 Score (Weighted): 0.06252900464826926
###################################################

Key: xgb_6_100_E_gpt4
Path: ../models/xgb_v1/6_100_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|023|033|003|093 | TP: 3, 1.97%; FN: 149; Total: 152
3|067|099|015|465 | TP: 465, 71.98%; FN: 181; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 023 & 033 & 003 & 093 \\
    \hline
    3 & 067 & 099 & 015 & 465 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.16666666666666666
Recall: 0.019736842105263157
F1 Score: 0.03529411764705882
------------------------------------------
Performance for category: 3
Precision: 0.8333333333333334
Recall: 0.7198142414860681
F1 Score: 0.7724252491694352
------------------------------------------
Number of Samples: 798
Accuracy: 0.5864661654135338
Precision (Weighted): 0.7063492063492064
Recall (Weighted): 0.5864661654135338
F1 Score (Weighted): 0.6320193193556493
###################################################

Key: bert_6_100_F_gpt4
Path: ../models/bert_v1/6_100_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|111|033|008 | TP: 33, 21.71%; FN: 119; Total: 152
2|389|152|105 | TP: 105, 16.25%; FN: 541; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 111 & 033 & 008 \\
    \hline
    2 & 389 & 152 & 105 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.1783783783783784
Recall: 0.21710526315789475
F1 Score: 0.19584569732937687
------------------------------------------
Performance for category: 2
Precision: 0.9292035398230089
Recall: 0.16253869969040247
F1 Score: 0.27667984189723316
------------------------------------------
Number of Samples: 798
Accuracy: 0.17293233082706766
Precision (Weighted): 0.786189223357365
Recall (Weighted): 0.17293233082706766
F1 Score (Weighted): 0.26128286197954625
###################################################

Key: xgb_6_100_F_gpt4
Path: ../models/xgb_v1/6_100_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|015|000|026|111 | TP: 26, 17.11%; FN: 126; Total: 152
3|040|001|084|521 | TP: 521, 80.65%; FN: 125; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 015 & 000 & 026 & 111 \\
    \hline
    3 & 040 & 001 & 084 & 521 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.23636363636363636
Recall: 0.17105263157894737
F1 Score: 0.1984732824427481
------------------------------------------
Performance for category: 3
Precision: 0.8243670886075949
Recall: 0.8065015479876161
F1 Score: 0.8153364632237871
------------------------------------------
Number of Samples: 798
Accuracy: 0.6854636591478697
Precision (Weighted): 0.712366431037317
Recall (Weighted): 0.6854636591478697
F1 Score (Weighted): 0.6978387145035891
###################################################

Key: bert_6_200_A_gpt4
Path: ../models/bert_v1/6_200_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|001|002|001|148 | TP: 1, 0.66%; FN: 151; Total: 152
3|005|005|003|633 | TP: 633, 97.99%; FN: 13; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 001 & 002 & 001 & 148 \\
    \hline
    3 & 005 & 005 & 003 & 633 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.25
Recall: 0.006578947368421052
F1 Score: 0.012820512820512818
------------------------------------------
Performance for category: 3
Precision: 0.8104993597951344
Recall: 0.9798761609907121
F1 Score: 0.8871758934828311
------------------------------------------
Number of Samples: 798
Accuracy: 0.7944862155388471
Precision (Weighted): 0.7037375769770136
Recall (Weighted): 0.7944862155388471
F1 Score (Weighted): 0.7206320114519132
###################################################

Key: xgb_6_200_A_gpt4
Path: ../models/xgb_v1/6_200_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|033|000|011|108 | TP: 11, 7.24%; FN: 141; Total: 152
3|072|001|023|550 | TP: 550, 85.14%; FN: 96; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 033 & 000 & 011 & 108 \\
    \hline
    3 & 072 & 001 & 023 & 550 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.3235294117647059
Recall: 0.07236842105263158
F1 Score: 0.11827956989247312
------------------------------------------
Performance for category: 3
Precision: 0.8358662613981763
Recall: 0.8513931888544891
F1 Score: 0.843558282208589
------------------------------------------
Number of Samples: 798
Accuracy: 0.7030075187969925
Precision (Weighted): 0.7382782900394199
Recall (Weighted): 0.7030075187969925
F1 Score (Weighted): 0.7054099560531384
###################################################

Key: bert_6_200_B_gpt4
Path: ../models/bert_v1/6_200_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|001|001|001|149 | TP: 1, 0.66%; FN: 151; Total: 152
3|006|005|003|632 | TP: 632, 97.83%; FN: 14; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 001 & 001 & 001 & 149 \\
    \hline
    3 & 006 & 005 & 003 & 632 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.25
Recall: 0.006578947368421052
F1 Score: 0.012820512820512818
------------------------------------------
Performance for category: 3
Precision: 0.8092189500640204
Recall: 0.978328173374613
F1 Score: 0.8857743517869655
------------------------------------------
Number of Samples: 798
Accuracy: 0.793233082706767
Precision (Weighted): 0.7027010548137309
Recall (Weighted): 0.793233082706767
F1 Score (Weighted): 0.7194974300790696
###################################################

Key: xgb_6_200_B_gpt4
Path: ../models/xgb_v1/6_200_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|030|000|122 | TP: 0, 0.0%; FN: 152; Total: 152
2|077|004|565 | TP: 565, 87.46%; FN: 81; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 030 & 000 & 122 \\
    \hline
    2 & 077 & 004 & 565 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.8224163027656477
Recall: 0.8746130030959752
F1 Score: 0.8477119279819956
------------------------------------------
Number of Samples: 798
Accuracy: 0.7080200501253133
Precision (Weighted): 0.6657655784293338
Recall (Weighted): 0.7080200501253133
F1 Score (Weighted): 0.6862429893187584
###################################################

Key: bert_6_200_C_gpt4
Path: ../models/bert_v1/6_200_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|003|001|001|147 | TP: 1, 0.66%; FN: 151; Total: 152
3|007|007|003|629 | TP: 629, 97.37%; FN: 17; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 003 & 001 & 001 & 147 \\
    \hline
    3 & 007 & 007 & 003 & 629 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.25
Recall: 0.006578947368421052
F1 Score: 0.012820512820512818
------------------------------------------
Performance for category: 3
Precision: 0.8105670103092784
Recall: 0.9736842105263158
F1 Score: 0.8846694796061885
------------------------------------------
Number of Samples: 798
Accuracy: 0.7894736842105263
Precision (Weighted): 0.7037923416789396
Recall (Weighted): 0.7894736842105263
F1 Score (Weighted): 0.7186030097422502
###################################################

Key: xgb_6_200_C_gpt4
Path: ../models/xgb_v1/6_200_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|029|000|006|117 | TP: 6, 3.95%; FN: 146; Total: 152
3|073|002|023|548 | TP: 548, 84.83%; FN: 98; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 029 & 000 & 006 & 117 \\
    \hline
    3 & 073 & 002 & 023 & 548 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.20689655172413793
Recall: 0.039473684210526314
F1 Score: 0.06629834254143646
------------------------------------------
Performance for category: 3
Precision: 0.8240601503759398
Recall: 0.848297213622291
F1 Score: 0.8360030511060259
------------------------------------------
Number of Samples: 798
Accuracy: 0.6942355889724311
Precision (Weighted): 0.7065051792041681
Recall (Weighted): 0.6942355889724311
F1 Score (Weighted): 0.6893926304270565
###################################################

Key: bert_6_200_D_gpt4
Path: ../models/bert_v1/6_200_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|002|001|001|148 | TP: 1, 0.66%; FN: 151; Total: 152
3|007|006|003|630 | TP: 630, 97.52%; FN: 16; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 002 & 001 & 001 & 148 \\
    \hline
    3 & 007 & 006 & 003 & 630 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.25
Recall: 0.006578947368421052
F1 Score: 0.012820512820512818
------------------------------------------
Performance for category: 3
Precision: 0.8097686375321337
Recall: 0.9752321981424149
F1 Score: 0.8848314606741574
------------------------------------------
Number of Samples: 798
Accuracy: 0.7907268170426065
Precision (Weighted): 0.7031460399069653
Recall (Weighted): 0.7907268170426065
F1 Score (Weighted): 0.7187341372734631
###################################################

Key: xgb_6_200_D_gpt4
Path: ../models/xgb_v1/6_200_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|028|020|104 | TP: 20, 13.16%; FN: 132; Total: 152
2|072|042|532 | TP: 532, 82.35%; FN: 114; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 028 & 020 & 104 \\
    \hline
    2 & 072 & 042 & 532 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.3225806451612903
Recall: 0.13157894736842105
F1 Score: 0.18691588785046728
------------------------------------------
Performance for category: 2
Precision: 0.8364779874213837
Recall: 0.8235294117647058
F1 Score: 0.8299531981279251
------------------------------------------
Number of Samples: 798
Accuracy: 0.6917293233082706
Precision (Weighted): 0.738592779371842
Recall (Weighted): 0.6917293233082706
F1 Score (Weighted): 0.7074699009322188
###################################################

Key: bert_6_200_E_gpt4
Path: ../models/bert_v1/6_200_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|001|003|003|145 | TP: 3, 1.97%; FN: 149; Total: 152
3|000|014|010|622 | TP: 622, 96.28%; FN: 24; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 001 & 003 & 003 & 145 \\
    \hline
    3 & 000 & 014 & 010 & 622 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.23076923076923078
Recall: 0.019736842105263157
F1 Score: 0.036363636363636355
------------------------------------------
Performance for category: 3
Precision: 0.8109517601043025
Recall: 0.9628482972136223
F1 Score: 0.8803963198867658
------------------------------------------
Number of Samples: 798
Accuracy: 0.7832080200501254
Precision (Weighted): 0.7004408021357174
Recall (Weighted): 0.7832080200501254
F1 Score (Weighted): 0.719628189691884
###################################################

Key: xgb_6_200_E_gpt4
Path: ../models/xgb_v1/6_200_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|020|006|059|067 | TP: 59, 38.82%; FN: 93; Total: 152
3|040|023|162|421 | TP: 421, 65.17%; FN: 225; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 020 & 006 & 059 & 067 \\
    \hline
    3 & 040 & 023 & 162 & 421 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.2669683257918552
Recall: 0.3881578947368421
F1 Score: 0.3163538873994638
------------------------------------------
Performance for category: 3
Precision: 0.8627049180327869
Recall: 0.651702786377709
F1 Score: 0.7425044091710759
------------------------------------------
Number of Samples: 798
Accuracy: 0.6015037593984962
Precision (Weighted): 0.7492312814154666
Recall (Weighted): 0.6015037593984962
F1 Score (Weighted): 0.6613328812145783
###################################################

Key: bert_6_200_F_gpt4
Path: ../models/bert_v1/6_200_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|001|002|003|146 | TP: 3, 1.97%; FN: 149; Total: 152
3|005|010|007|624 | TP: 624, 96.59%; FN: 22; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 001 & 002 & 003 & 146 \\
    \hline
    3 & 005 & 010 & 007 & 624 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.3
Recall: 0.019736842105263157
F1 Score: 0.037037037037037035
------------------------------------------
Performance for category: 3
Precision: 0.8103896103896104
Recall: 0.9659442724458205
F1 Score: 0.8813559322033899
------------------------------------------
Number of Samples: 798
Accuracy: 0.7857142857142857
Precision (Weighted): 0.7131725417439704
Recall (Weighted): 0.7857142857142857
F1 Score (Weighted): 0.720533285505037
###################################################

Key: xgb_6_200_F_gpt4
Path: ../models/xgb_v1/6_200_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|036|002|008|106 | TP: 8, 5.26%; FN: 144; Total: 152
3|091|003|029|523 | TP: 523, 80.96%; FN: 123; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 036 & 002 & 008 & 106 \\
    \hline
    3 & 091 & 003 & 029 & 523 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.21621621621621623
Recall: 0.05263157894736842
F1 Score: 0.08465608465608465
------------------------------------------
Performance for category: 3
Precision: 0.8314785373608903
Recall: 0.8095975232198143
F1 Score: 0.8203921568627451
------------------------------------------
Number of Samples: 798
Accuracy: 0.6654135338345865
Precision (Weighted): 0.7142857142857143
Recall (Weighted): 0.6654135338345865
F1 Score (Weighted): 0.680251952632905
###################################################

Key: bert_6_400_A_gpt4
Path: ../models/bert_v1/6_400_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|007|000|145 | TP: 0, 0.0%; FN: 152; Total: 152
2|027|000|619 | TP: 619, 95.82%; FN: 27; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 007 & 000 & 145 \\
    \hline
    2 & 027 & 000 & 619 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.8102094240837696
Recall: 0.958204334365325
F1 Score: 0.8780141843971631
------------------------------------------
Number of Samples: 798
Accuracy: 0.7756892230576441
Precision (Weighted): 0.655883819496385
Recall (Weighted): 0.7756892230576441
F1 Score (Weighted): 0.710773387369132
###################################################

Key: xgb_6_400_A_gpt4
Path: ../models/xgb_v1/6_400_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|036|003|018|095 | TP: 18, 11.84%; FN: 134; Total: 152
3|106|008|056|476 | TP: 476, 73.68%; FN: 170; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 036 & 003 & 018 & 095 \\
    \hline
    3 & 106 & 008 & 056 & 476 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.24324324324324326
Recall: 0.11842105263157894
F1 Score: 0.1592920353982301
------------------------------------------
Performance for category: 3
Precision: 0.8336252189141856
Recall: 0.7368421052631579
F1 Score: 0.7822514379622021
------------------------------------------
Number of Samples: 798
Accuracy: 0.6190476190476191
Precision (Weighted): 0.7211715092625776
Recall (Weighted): 0.6190476190476191
F1 Score (Weighted): 0.6635925041404932
###################################################

Key: bert_6_400_B_gpt4
Path: ../models/bert_v1/6_400_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|015|000|137 | TP: 0, 0.0%; FN: 152; Total: 152
2|030|000|616 | TP: 616, 95.36%; FN: 30; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 015 & 000 & 137 \\
    \hline
    2 & 030 & 000 & 616 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.8180610889774237
Recall: 0.9535603715170279
F1 Score: 0.8806290207290922
------------------------------------------
Number of Samples: 798
Accuracy: 0.7719298245614035
Precision (Weighted): 0.6622399291722002
Recall (Weighted): 0.7719298245614035
F1 Score (Weighted): 0.7128901596378365
###################################################

Key: xgb_6_400_B_gpt4
Path: ../models/xgb_v1/6_400_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|024|002|022|104 | TP: 22, 14.47%; FN: 130; Total: 152
3|058|001|061|526 | TP: 526, 81.42%; FN: 120; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 024 & 002 & 022 & 104 \\
    \hline
    3 & 058 & 001 & 061 & 526 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.26506024096385544
Recall: 0.14473684210526316
F1 Score: 0.18723404255319148
------------------------------------------
Performance for category: 3
Precision: 0.834920634920635
Recall: 0.8142414860681114
F1 Score: 0.8244514106583072
------------------------------------------
Number of Samples: 798
Accuracy: 0.6867167919799498
Precision (Weighted): 0.7263757979764864
Recall (Weighted): 0.6867167919799498
F1 Score (Weighted): 0.7030766738763803
###################################################

Key: bert_6_400_C_gpt4
Path: ../models/bert_v1/6_400_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|006|000|146 | TP: 0, 0.0%; FN: 152; Total: 152
2|022|000|624 | TP: 624, 96.59%; FN: 22; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 006 & 000 & 146 \\
    \hline
    2 & 022 & 000 & 624 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.8103896103896104
Recall: 0.9659442724458205
F1 Score: 0.8813559322033899
------------------------------------------
Number of Samples: 798
Accuracy: 0.7819548872180451
Precision (Weighted): 0.6560296846011132
Recall (Weighted): 0.7819548872180451
F1 Score (Weighted): 0.7134786117836966
###################################################

Key: xgb_6_400_C_gpt4
Path: ../models/xgb_v1/6_400_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|017|000|016|119 | TP: 16, 10.53%; FN: 136; Total: 152
3|039|001|039|567 | TP: 567, 87.77%; FN: 79; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 017 & 000 & 016 & 119 \\
    \hline
    3 & 039 & 001 & 039 & 567 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.2909090909090909
Recall: 0.10526315789473684
F1 Score: 0.15458937198067632
------------------------------------------
Performance for category: 3
Precision: 0.826530612244898
Recall: 0.8777089783281734
F1 Score: 0.8513513513513514
------------------------------------------
Number of Samples: 798
Accuracy: 0.7305764411027569
Precision (Weighted): 0.724507465323792
Recall (Weighted): 0.7305764411027569
F1 Score (Weighted): 0.7186347838521752
###################################################

Key: bert_6_400_D_gpt4
Path: ../models/bert_v1/6_400_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|011|000|141 | TP: 0, 0.0%; FN: 152; Total: 152
2|025|000|621 | TP: 621, 96.13%; FN: 25; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 011 & 000 & 141 \\
    \hline
    2 & 025 & 000 & 621 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.8149606299212598
Recall: 0.9613003095975232
F1 Score: 0.8821022727272728
------------------------------------------
Number of Samples: 798
Accuracy: 0.7781954887218046
Precision (Weighted): 0.6597300337457818
Recall (Weighted): 0.7781954887218046
F1 Score (Weighted): 0.7140827922077922
###################################################

Key: xgb_6_400_D_gpt4
Path: ../models/xgb_v1/6_400_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|017|003|024|108 | TP: 24, 15.79%; FN: 128; Total: 152
3|040|001|044|561 | TP: 561, 86.84%; FN: 85; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 017 & 003 & 024 & 108 \\
    \hline
    3 & 040 & 001 & 044 & 561 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.35294117647058826
Recall: 0.15789473684210525
F1 Score: 0.21818181818181817
------------------------------------------
Performance for category: 3
Precision: 0.8385650224215246
Recall: 0.868421052631579
F1 Score: 0.853231939163498
------------------------------------------
Number of Samples: 798
Accuracy: 0.7330827067669173
Precision (Weighted): 0.7460652422403939
Recall (Weighted): 0.7330827067669173
F1 Score (Weighted): 0.7322700113574638
###################################################

Key: bert_6_400_E_gpt4
Path: ../models/bert_v1/6_400_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|016|000|136 | TP: 0, 0.0%; FN: 152; Total: 152
2|045|000|601 | TP: 601, 93.03%; FN: 45; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 016 & 000 & 136 \\
    \hline
    2 & 045 & 000 & 601 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.8154681139755766
Recall: 0.9303405572755418
F1 Score: 0.8691250903832248
------------------------------------------
Number of Samples: 798
Accuracy: 0.7531328320802005
Precision (Weighted): 0.6601408541707049
Recall (Weighted): 0.7531328320802005
F1 Score (Weighted): 0.7035774541197535
###################################################

Key: xgb_6_400_E_gpt4
Path: ../models/xgb_v1/6_400_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|050|002|017|083 | TP: 17, 11.18%; FN: 135; Total: 152
3|149|003|035|459 | TP: 459, 71.05%; FN: 187; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 050 & 002 & 017 & 083 \\
    \hline
    3 & 149 & 003 & 035 & 459 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.3269230769230769
Recall: 0.1118421052631579
F1 Score: 0.16666666666666666
------------------------------------------
Performance for category: 3
Precision: 0.8468634686346863
Recall: 0.7105263157894737
F1 Score: 0.7727272727272727
------------------------------------------
Number of Samples: 798
Accuracy: 0.5964912280701754
Precision (Weighted): 0.7478272035467607
Recall (Weighted): 0.5964912280701754
F1 Score (Weighted): 0.6572871572871573
###################################################

Key: bert_6_400_F_gpt4
Path: ../models/bert_v1/6_400_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|020|000|132 | TP: 0, 0.0%; FN: 152; Total: 152
2|056|000|590 | TP: 590, 91.33%; FN: 56; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 020 & 000 & 132 \\
    \hline
    2 & 056 & 000 & 590 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.817174515235457
Recall: 0.913312693498452
F1 Score: 0.8625730994152047
------------------------------------------
Number of Samples: 798
Accuracy: 0.7393483709273183
Precision (Weighted): 0.6615222266191795
Recall (Weighted): 0.7393483709273183
F1 Score (Weighted): 0.6982734614313562
###################################################

Key: xgb_6_400_F_gpt4
Path: ../models/xgb_v1/6_400_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|017|004|011|120 | TP: 11, 7.24%; FN: 141; Total: 152
3|034|023|039|550 | TP: 550, 85.14%; FN: 96; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 017 & 004 & 011 & 120 \\
    \hline
    3 & 034 & 023 & 039 & 550 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.22
Recall: 0.07236842105263158
F1 Score: 0.1089108910891089
------------------------------------------
Performance for category: 3
Precision: 0.8208955223880597
Recall: 0.8513931888544891
F1 Score: 0.8358662613981762
------------------------------------------
Number of Samples: 798
Accuracy: 0.7030075187969925
Precision (Weighted): 0.7064392324093817
Recall (Weighted): 0.7030075187969925
F1 Score (Weighted): 0.6973985718154968
###################################################

Key: bert_6_800_A_gpt4
Path: ../models/bert_v1/6_800_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|001|012|139 | TP: 12, 7.89%; FN: 140; Total: 152
2|004|031|611 | TP: 611, 94.58%; FN: 35; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 001 & 012 & 139 \\
    \hline
    2 & 004 & 031 & 611 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.27906976744186046
Recall: 0.07894736842105263
F1 Score: 0.12307692307692308
------------------------------------------
Performance for category: 2
Precision: 0.8146666666666667
Recall: 0.9458204334365325
F1 Score: 0.8753581661891118
------------------------------------------
Number of Samples: 798
Accuracy: 0.7807017543859649
Precision (Weighted): 0.7126482096714656
Recall (Weighted): 0.7807017543859649
F1 Score (Weighted): 0.7320665008344093
###################################################

Key: xgb_6_800_A_gpt4
Path: ../models/xgb_v1/6_800_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|017|002|032|101 | TP: 32, 21.05%; FN: 120; Total: 152
3|037|008|048|553 | TP: 553, 85.6%; FN: 93; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 017 & 002 & 032 & 101 \\
    \hline
    3 & 037 & 008 & 048 & 553 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.4
Recall: 0.21052631578947367
F1 Score: 0.27586206896551724
------------------------------------------
Performance for category: 3
Precision: 0.845565749235474
Recall: 0.8560371517027864
F1 Score: 0.8507692307692308
------------------------------------------
Number of Samples: 798
Accuracy: 0.7330827067669173
Precision (Weighted): 0.7606960827144312
Recall (Weighted): 0.7330827067669173
F1 Score (Weighted): 0.7412631047113806
###################################################

Key: bert_6_800_B_gpt4
Path: ../models/bert_v1/6_800_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|002|028|122 | TP: 28, 18.42%; FN: 124; Total: 152
2|006|085|555 | TP: 555, 85.91%; FN: 91; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 002 & 028 & 122 \\
    \hline
    2 & 006 & 085 & 555 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.24778761061946902
Recall: 0.18421052631578946
F1 Score: 0.21132075471698114
------------------------------------------
Performance for category: 2
Precision: 0.8197932053175776
Recall: 0.8591331269349846
F1 Score: 0.8390022675736962
------------------------------------------
Number of Samples: 798
Accuracy: 0.7305764411027569
Precision (Weighted): 0.7108397587084142
Recall (Weighted): 0.7305764411027569
F1 Score (Weighted): 0.719443884172417
###################################################

Key: xgb_6_800_B_gpt4
Path: ../models/xgb_v1/6_800_B_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|022|003|008|119 | TP: 8, 5.26%; FN: 144; Total: 152
3|041|017|012|576 | TP: 576, 89.16%; FN: 70; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 022 & 003 & 008 & 119 \\
    \hline
    3 & 041 & 017 & 012 & 576 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.4
Recall: 0.05263157894736842
F1 Score: 0.09302325581395349
------------------------------------------
Performance for category: 3
Precision: 0.8287769784172662
Recall: 0.891640866873065
F1 Score: 0.8590604026845637
------------------------------------------
Number of Samples: 798
Accuracy: 0.731829573934837
Precision (Weighted): 0.7471051730044534
Recall (Weighted): 0.731829573934837
F1 Score (Weighted): 0.7131485651853998
###################################################

Key: bert_6_800_C_gpt4
Path: ../models/bert_v1/6_800_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|003|048|101 | TP: 48, 31.58%; FN: 104; Total: 152
2|011|115|520 | TP: 520, 80.5%; FN: 126; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 003 & 048 & 101 \\
    \hline
    2 & 011 & 115 & 520 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.294478527607362
Recall: 0.3157894736842105
F1 Score: 0.3047619047619048
------------------------------------------
Performance for category: 2
Precision: 0.8373590982286635
Recall: 0.804953560371517
F1 Score: 0.8208366219415943
------------------------------------------
Number of Samples: 798
Accuracy: 0.7117794486215538
Precision (Weighted): 0.7339532752531776
Recall (Weighted): 0.7117794486215538
F1 Score (Weighted): 0.7225366758121298
###################################################

Key: xgb_6_800_C_gpt4
Path: ../models/xgb_v1/6_800_C_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|024|000|033|095 | TP: 33, 21.71%; FN: 119; Total: 152
3|055|001|065|525 | TP: 525, 81.27%; FN: 121; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 024 & 000 & 033 & 095 \\
    \hline
    3 & 055 & 001 & 065 & 525 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.336734693877551
Recall: 0.21710526315789475
F1 Score: 0.264
------------------------------------------
Performance for category: 3
Precision: 0.8467741935483871
Recall: 0.8126934984520123
F1 Score: 0.8293838862559242
------------------------------------------
Number of Samples: 798
Accuracy: 0.6992481203007519
Precision (Weighted): 0.7496238126587039
Recall (Weighted): 0.6992481203007519
F1 Score (Weighted): 0.7216917174452719
###################################################

Key: bert_6_800_D_gpt4
Path: ../models/bert_v1/6_800_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|006|006|140 | TP: 6, 3.95%; FN: 146; Total: 152
2|017|008|621 | TP: 621, 96.13%; FN: 25; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 006 & 006 & 140 \\
    \hline
    2 & 017 & 008 & 621 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.42857142857142855
Recall: 0.039473684210526314
F1 Score: 0.07228915662650602
------------------------------------------
Performance for category: 2
Precision: 0.8160315374507228
Recall: 0.9613003095975232
F1 Score: 0.8827292110874201
------------------------------------------
Number of Samples: 798
Accuracy: 0.7857142857142857
Precision (Weighted): 0.7422296119499048
Recall (Weighted): 0.7857142857142857
F1 Score (Weighted): 0.7283596769043889
###################################################

Key: xgb_6_800_D_gpt4
Path: ../models/xgb_v1/6_800_D_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|025|001|014|112 | TP: 14, 9.21%; FN: 138; Total: 152
3|066|009|047|524 | TP: 524, 81.11%; FN: 122; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 025 & 001 & 014 & 112 \\
    \hline
    3 & 066 & 009 & 047 & 524 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.22950819672131148
Recall: 0.09210526315789473
F1 Score: 0.13145539906103285
------------------------------------------
Performance for category: 3
Precision: 0.8238993710691824
Recall: 0.8111455108359134
F1 Score: 0.8174726989079564
------------------------------------------
Number of Samples: 798
Accuracy: 0.6741854636591479
Precision (Weighted): 0.7106820045267308
Recall (Weighted): 0.6741854636591479
F1 Score (Weighted): 0.686802737032352
###################################################

Key: bert_6_800_E_gpt4
Path: ../models/bert_v1/6_800_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|002|004|146 | TP: 4, 2.63%; FN: 148; Total: 152
2|005|021|620 | TP: 620, 95.98%; FN: 26; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 002 & 004 & 146 \\
    \hline
    2 & 005 & 021 & 620 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.16
Recall: 0.02631578947368421
F1 Score: 0.04519774011299435
------------------------------------------
Performance for category: 2
Precision: 0.8093994778067886
Recall: 0.9597523219814241
F1 Score: 0.8781869688385269
------------------------------------------
Number of Samples: 798
Accuracy: 0.7819548872180451
Precision (Weighted): 0.6857043391769241
Recall (Weighted): 0.7819548872180451
F1 Score (Weighted): 0.7195223538431873
###################################################

Key: xgb_6_800_E_gpt4
Path: ../models/xgb_v1/6_800_E_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|016|013|025|098 | TP: 25, 16.45%; FN: 127; Total: 152
3|029|038|075|504 | TP: 504, 78.02%; FN: 142; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 016 & 013 & 025 & 098 \\
    \hline
    3 & 029 & 038 & 075 & 504 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.25
Recall: 0.16447368421052633
F1 Score: 0.19841269841269843
------------------------------------------
Performance for category: 3
Precision: 0.8372093023255814
Recall: 0.7801857585139319
F1 Score: 0.8076923076923077
------------------------------------------
Number of Samples: 798
Accuracy: 0.6629072681704261
Precision (Weighted): 0.7253599114064231
Recall (Weighted): 0.6629072681704261
F1 Score (Weighted): 0.691639048781906
###################################################

Key: bert_6_800_F_gpt4
Path: ../models/bert_v1/6_800_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|011|038|103 | TP: 38, 25.0%; FN: 114; Total: 152
2|033|119|494 | TP: 494, 76.47%; FN: 152; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 011 & 038 & 103 \\
    \hline
    2 & 033 & 119 & 494 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.24203821656050956
Recall: 0.25
F1 Score: 0.2459546925566343
------------------------------------------
Performance for category: 2
Precision: 0.8274706867671692
Recall: 0.7647058823529411
F1 Score: 0.7948511665325824
------------------------------------------
Number of Samples: 798
Accuracy: 0.6666666666666666
Precision (Weighted): 0.7159597400611388
Recall (Weighted): 0.6666666666666666
F1 Score (Weighted): 0.6902994572038302
###################################################

Key: xgb_6_800_F_gpt4
Path: ../models/xgb_v1/6_800_F_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|019|001|038|094 | TP: 38, 25.0%; FN: 114; Total: 152
3|050|007|100|489 | TP: 489, 75.7%; FN: 157; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 019 & 001 & 038 & 094 \\
    \hline
    3 & 050 & 007 & 100 & 489 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.2753623188405797
Recall: 0.25
F1 Score: 0.2620689655172414
------------------------------------------
Performance for category: 3
Precision: 0.8387650085763293
Recall: 0.7569659442724458
F1 Score: 0.7957689178193653
------------------------------------------
Number of Samples: 798
Accuracy: 0.6604010025062657
Precision (Weighted): 0.7314502105314246
Recall (Weighted): 0.6604010025062657
F1 Score (Weighted): 0.6941117840475322
###################################################

Key: bert_6_1600_A_gpt4
Path: ../models/bert_v1/6_1600_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|005|019|128 | TP: 19, 12.5%; FN: 133; Total: 152
2|011|052|583 | TP: 583, 90.25%; FN: 63; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 005 & 019 & 128 \\
    \hline
    2 & 011 & 052 & 583 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.2676056338028169
Recall: 0.125
F1 Score: 0.17040358744394618
------------------------------------------
Performance for category: 2
Precision: 0.819971870604782
Recall: 0.9024767801857585
F1 Score: 0.8592483419307296
------------------------------------------
Number of Samples: 798
Accuracy: 0.7543859649122807
Precision (Weighted): 0.7147592540710744
Recall (Weighted): 0.7543859649122807
F1 Score (Weighted): 0.7280398172665804
###################################################

Key: xgb_6_1600_A_gpt4
Path: ../models/xgb_v1/6_1600_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|011|002|047|092 | TP: 47, 30.92%; FN: 105; Total: 152
3|025|013|116|492 | TP: 492, 76.16%; FN: 154; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 011 & 002 & 047 & 092 \\
    \hline
    3 & 025 & 013 & 116 & 492 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.2883435582822086
Recall: 0.3092105263157895
F1 Score: 0.2984126984126984
------------------------------------------
Performance for category: 3
Precision: 0.8424657534246576
Recall: 0.7616099071207431
F1 Score: 0.8
------------------------------------------
Number of Samples: 798
Accuracy: 0.6754385964912281
Precision (Weighted): 0.7369186686356197
Recall (Weighted): 0.6754385964912281
F1 Score (Weighted): 0.7044595616024188
###################################################

Key: bert_6_3200_A_gpt4
Path: ../models/bert_v1/6_3200_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000
1|000|003|149 | TP: 3, 1.97%; FN: 149; Total: 152
2|004|007|635 | TP: 635, 98.3%; FN: 11; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 003 & 149 \\
    \hline
    2 & 004 & 007 & 635 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.3
Recall: 0.019736842105263157
F1 Score: 0.037037037037037035
------------------------------------------
Performance for category: 2
Precision: 0.8099489795918368
Recall: 0.9829721362229102
F1 Score: 0.8881118881118881
------------------------------------------
Number of Samples: 798
Accuracy: 0.7994987468671679
Precision (Weighted): 0.712815840621963
Recall (Weighted): 0.7994987468671679
F1 Score (Weighted): 0.7260023926690593
###################################################

Key: xgb_6_3200_A_gpt4
Path: ../models/xgb_v1/6_3200_A_gpt4/
-------------------------------------
 | 0 | 1 | 2 | 3
-------------------
0|000|000|000|000
1|000|000|000|000
2|020|003|043|086 | TP: 43, 28.29%; FN: 109; Total: 152
3|034|017|109|486 | TP: 486, 75.23%; FN: 160; Total: 646
-------------------------------------
LaTeX:
\begin{tabular}{|c|c|c|c|c|}
    \hline
        & 0 & 1 & 2 & 3 \\
    \hline
    0 & 000 & 000 & 000 & 000 \\
    \hline
    1 & 000 & 000 & 000 & 000 \\
    \hline
    2 & 020 & 003 & 043 & 086 \\
    \hline
    3 & 034 & 017 & 109 & 486 \\
    \hline
\end{tabular}
-------------------------------------
Performance for category: 0
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 1
Precision: 0.0
Recall: 0.0
F1 Score: 0.0
------------------------------------------
Performance for category: 2
Precision: 0.28289473684210525
Recall: 0.28289473684210525
F1 Score: 0.28289473684210525
------------------------------------------
Performance for category: 3
Precision: 0.8496503496503497
Recall: 0.7523219814241486
F1 Score: 0.7980295566502463
------------------------------------------
Number of Samples: 798
Accuracy: 0.6629072681704261
Precision (Weighted): 0.7416968995916364
Recall (Weighted): 0.6629072681704261
F1 Score (Weighted): 0.6999086385915527
###################################################

