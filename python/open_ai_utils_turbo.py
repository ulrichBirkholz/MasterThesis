from typing import List, Iterator, Generator, Dict
from json.decoder import JSONDecodeError
import openai
import time
from openai.error import OpenAIError, RateLimitError
import re
import json
#import config
import logging as log
import re
from tsv_utils import Answer, Question, KeyElement
import hashlib
import tiktoken
import random
from dataclasses import dataclass

@dataclass
class SampleGoal:
    number_of_key_elements: int
    task: str

@dataclass
class SampleRole:
    role: str
    idiom_category: str

#CHAT_GPT_MODEL = "text-davinci-003"
CHAT_GPT_MODEL = "gpt-3.5-turbo" #-> refuses to produce incorrect answers

def _count_token(messages: List[Dict]) -> int:
    enc = tiktoken.encoding_for_model(CHAT_GPT_MODEL)
    return sum([len(enc.encode(message["content"])) for message in messages])

def generate_samples(api_key, question:Question, key_elements:List[KeyElement]) -> Generator[List[Answer], None, None]:
    openai.api_key = api_key

    for prompt in generate_answer_prompt(question, key_elements):
        retries = 0
        max_retries = 5
        while retries < max_retries:
            try:
                yield _generate_sample(
                        question, prompt)
                break
            except JSONDecodeError as e:
                retries += 1
                log.error(
                    f"Unable to parse JSON response: {e}")
            except Exception as e:
                retries += 1
                log.error(
                    f"Unable to generate Answers: {e}")

        if retries >= max_retries:
            log.error(f"Exceeded {max_retries} retries, the creation of answers for the question {question.question_id} will be aborted")

def _execute_api_call(messages, max_tokens, temperature, frequency_penalty, presence_penalty):
    retries = 0
    max_retries = 3600
    while retries < max_retries:
        try:
            return openai.ChatCompletion.create(
                model=CHAT_GPT_MODEL,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
                frequency_penalty=frequency_penalty,
                presence_penalty=presence_penalty,
                n=1,
                stop=None
            )
        except RateLimitError as e:
            retries += 1
            sleep_duration = 10
            log.warning(f"Rate limit hit: {str(e)}. Sleeping for {sleep_duration} before starting retry number: {retries}")
            time.sleep(sleep_duration)
        except OpenAIError as e:
            retries += 1
            sleep_duration = 10
            log.warning(f"Received OpenAIError: {str(e)}. Sleeping for {sleep_duration} before starting retry number: {retries}")
            time.sleep(sleep_duration)
        except Exception as e:
            log.error(f"An Exception ocurred while calling OpenAI: {str(e)}, Aborting the process.")
            raise e

    if retries >= max_retries:
        log.error(f"To many retries")

def _add_key_elements(key_elements:List[KeyElement]) -> str:
    if len(key_elements) > 0:
        result = "The key elements for this task are:"
        for element in key_elements:
            result += f"\n- {element.element}"
    return result

def _setup_goal(category:SampleGoal, key_elements:List[KeyElement]):
    line = f"{category.task}"
    random_elements = random.sample(key_elements, category.number_of_key_elements)
    if len(random_elements) > 0:
        line += ":"
        for element in random_elements:
            line += f"\n- {element.element}"
    return line


def _add_idioms(idioms, idiom_category):
    if idiom_category is None or idiom_category not in idioms:
        return ""
    
    selection = random.sample(idioms[idiom_category], 3)
    result = "Use idioms such as:"
    for idiom in selection:
        result += f"\n- {idiom}"
    return result

# 10 x 21 x 20 = 4200 individual prompts
# The wording has been enhanced with the assistance of Chat-GPT, optimizing their comprehensibility for Davinci-003.
# The elements use a simple phrasing to make them easily understandable

# Some of the combinations appear to be contradictory such as experts providing off-topic explanations
# but at this point it is more about the language-style, generated by the AI.

#TODO: -> generate_answer_messages
def generate_answer_prompt(question:Question, key_elements:List[KeyElement]):

    # 10 categories of correctness defined as goals within the prompt
    # NOTE: it does not work to provide a list and instruct the AI to choose a number of entries -> we need to provide just the entries
    # NOTE: it does not work to provide a list and instruct the AI to avoid any of its entries.
    sample_goals = [
        SampleGoal(0, "Imagine you're playing a character in a play who always gets facts wrong and strays off-topic. How would that character answer the following?"),
        SampleGoal(0, "Suppose you had the opposite of your training data — filled with incorrect facts and tangential thoughts. From that perspective, how would you respond to this?"),
        SampleGoal(0, "Produce the example of an entirely incorrect and off-topic answer"),
        SampleGoal(0, "Produce the example of an entirely incorrect answer that contradicts established scientific understanding."),
        SampleGoal(0, "The answer must be an analogy or metaphor to demonstrate comprehension."),
        SampleGoal(1 + question.score_offset, "The answer must include a paraphrase of all of the following information in the response."),
        SampleGoal(2 + question.score_offset, "The answer must include a paraphrase of all of the following information in the response."),
        SampleGoal(3 + question.score_offset, "The answer must include a paraphrase of all of the following information in the response."),
        SampleGoal(3 + question.score_offset, "The answer must include a paraphrase of all of the following information in an unrelated or incorrect context in the response."),
        SampleGoal(random.randint(3 + question.score_offset, len(key_elements)), "The answer must include a paraphrase of all of the following information in the response."),
        SampleGoal(random.randint(1, len(key_elements)), "The answer must include a paraphrase of all of the following information but deviate from the main topic in the response."),
        SampleGoal(len(key_elements), "The answer must contradict any of the following information, with reasoning.")
    ]

    # 21 combinations of tone syntax, mood, voice and style
    # This could be broken down in tones ["Neutral", ...] 
    #   and syntaxes ["complex scientific jargon", ...] 
    #   to further increase the number of variations of styles

    # NOTE: The AI is unable to follow to many instructions properly
    styles = [
        "Neutral tone with complex scientific jargon",
        "Academic tone with simple, direct language",
        "Didactic tone with compound sentences",
        "Curious tone with question-based syntax",
        "Energetic tone with assertive language",
        "Respectful tone with active syntax",
        "Critical tone with passive syntax",
        "Honest tone with concise syntax",
        "Enthusiastic tone with cause-and-effect syntax",
        "Pragmatic tone with precise syntax",
        "Serene tone with layered syntax",
        "Serious tone with procedural syntax",
        "Imaginative tone with parallel syntax",
        "Contemplative tone with contrasting syntax",
        "Clear tone with concise syntax",
        "Realistic tone with technical syntax",
        "Optimistic tone with balanced syntax",
        "Concise tone with analytical syntax",
        "Engaging tone with narrative syntax",
        "Curious tone with question-based syntax"
        "Brief, less than 8 words"
    ]

    # this is less about accuracy and more about the incorporations of idioms in general
    idioms = {
        "category_1": [
            "All hat, no cattle",  # All talk and no action
            "As useful as a chocolate teapot",  # Useless
            "A hard row to hoe",  # A difficult task
            "That dog won't hunt",  # That idea won't work
            "Slower than molasses in January",  # Very slow
            "Like two peas in a pod",  # Very similar
            "Cute as a button",  # Very cute
            "Barking up the wrong tree",  # Misdirected efforts
            "Like finding a needle in a haystack",  # Extremely hard to find
            "Faster than a one-legged man in a butt-kicking contest"  # Very fast
        ],
        "category_2": [
            "Bite the bullet",  # Face a difficult situation
            "Hit the nail on the head",  # Exactly right
            "When pigs fly",  # Never
            "You can't judge a book by its cover",  # Don't prejudge
            "Once in a blue moon",  # Very rarely
            "You can't make an omelette without breaking eggs",  # It's impossible to achieve something important without causing some problems
            "Let the cat out of the bag", # Reveal a secret
            "Kill two birds with one stone", # Achieve two tasks simultaneously
            "Cutting corners" # Skipping steps to save time
        ],
        "category_3": [
            "Sweet nanny goat a go run him belly",  # Getting too much of a good thing can lead to trouble
            "Every mikkle mek a mukkle",  # Every little bit counts
            "Stone under water nuh know when sun hot" # Those isolated from changes remain unaware of them.
            "Chicken merry, hawk deh near" # Every action has a reaction, often seen in physics.
            "Ripe fruit must drop" # Natural processes follow a certain order.
            "When the river is silent, it’s either dried up or it’s becoming a flood" # An apparent lack of change can indicate stability or impending drastic change.
            "New broom sweeps clean, but old broom knows every corner" # While new techniques may appear superior, traditional methods often have proven effectiveness based on extensive experience.
            "One hand can't clap",  # It takes cooperation to achieve a task
            "Every day bucket a go well, one day the bottom must drop out" # Systems that are stressed continuously will eventually fail.
            "Frog say, what is joke to children is death to him" # The impact of actions can vary dramatically depending on perspective.
        ],
        "category_4": [
            "Up and at 'em",  # Get started
            "Colder than a witch's teat in a brass bra",  # Very cold
            "Off like a herd of turtles",  # Starting very slowly
            "In a coon's age",  # In a long time
            "Does a one-legged duck swim in circles?",  # Obvious answer is yes
            "Like herding cats",  # Trying to control an uncontrollable situation
            "Faster than a jackrabbit on a date",  # Very fast
            "Tight as bark on a tree",  # Stingy or frugal
            "Finer than frog hair",  # Very fine or delicate
            "Like trying to put lipstick on a pig"  # Trying to make something unattractive look attractive
        ],
        "category_5": [
            "Nae wind, nae wave", # No influence, no effects
            "Mony a mickle maks a muckle", # Many small things accumulate to something big
            "It's mince",  # It's rubbish or nonsense    
            "Cold enough to freeze the balls off a brass monkey", # Extremely cold
            "As damp as a dungeon", # Extremely wet or humid
            "As thin as a rake", # Extremely thin or slender
            "As high as a kite", # Very high
            "Heavy as a lead balloon", # Extremely heavy
            "Round as a pease", # Perfectly round
            "Strong as a lion" # Extremely strong
        ],
        "category_6": [
            "Colder than a witch's tit", # Extremely cold
            "Smaller than a clam's hindquarters", # Extremely small
            "Faster than a car on the Pike", # Very fast
            "Higher than Hancock tower", # Very high
            "Sharper than a Sox fan's wit", # Very sharp
            "Denser than chowder", # Very dense or thick
            "Slower than molasses in January", # Very slow
            "Stronger than a Southie dockworker", # Very strong
            "Hotter than a T platform in August", # Extremely hot
            "Quieter than a midnight in the Commons" # Very quiet
        ],
        "category_7": [
            "A leopard doesn't change its spots", # Immutable properties
            "Small-small", # Miniscule or incremental
            "Veld fire", # Rapid uncontrollable reaction
            "Cold as a Jo'burg morning", # Very cold
            "High as the Drakensberg", # Very high
            "Dry as the Karoo", # Very dry or arid
            "Quick-quick", # Quickly, swiftly
            "Slow as a wet week", # Very slow
            "Strong as a lion", # Very strong
            "Light as a feather", # Very light
        ],
        "category_8": [
            "Bigger than a prairie sky", # Extremely large or expansive
            "Cold as a Yukon winter", # Extremely cold or chilling
            "Swift as a Calgary wind", # Very fast or rapid
            "As changeable as Maritime weather", # Highly variable or changeable
            "Solid as Canadian Shield", # Extremely sturdy or stable
            "Heavy as a moose", # Extremely heavy or substantial
            "Steady as a Canuck's resolve", # Extremely steady or stable
            "Twisted as Toronto's streets", # Complicated or convoluted
            "Hot as Toronto in July", # Extremely hot or sweltering
            "Tight as a beaver's dam" # Extremely compact or close-fitted
        ],
        "category_9": [
            "Arseways",  # To do something the wrong way
            "Bang on",  # Correct, right
            "Donkey's years",  # A long time
            "On the never never",  # Buying on hire purchase
            "Puck",  # To hit, punch or thump something
            "Quare",  # Very, extremely
            "Like hen's teeth", # Extremely rare
            "Wet as an otter's pocket", # Extremely wet
            "As fast as greased lightning", # Extremely fast
            "As solid as the Rock of Cashel" # Very solid/stable
        ]
    }

    # 20 roles the AI embodies by creating the answers
    # The AI is unable to just incorporate idioms, we need to provide examples
    roles = [
        # Beginner
        SampleRole("an American Southerner using regional vernacular, new to the subject", "category_1"),
        SampleRole("an ESL student with basic English skills, discovering the subject", "category_2"),
        SampleRole("a Caribbean native with beginner English skills, learning the subject with Creole influences", "category_3"),
        SampleRole("an English-speaking student learning the topic for the first time", None),
        SampleRole("a non-native English speaker with limited English, navigating basic concepts of the topic", "category_2"),
        
        # Intermediate
        SampleRole("an American Midwesterner with intermediate subject knowledge, using regional dialect", "category_4"),
        SampleRole("a Scot with foundational subject knowledge, integrating Scottish slang", "category_5"),
        SampleRole("an British English speaker studying the topic at an intermediate level", None),
        SampleRole("an undergraduate student with a basic grasp on the subject", None),
        SampleRole("a non-specialist approaching the subject from a different field's perspective", None),

        # Advanced
        SampleRole("a british English speaking senior researcher with considerable subject knowledge", None),
        SampleRole("a Bostonian with substantial understanding of the subject, using local dialect", "category_6"),
        SampleRole("a South African with significant subject understanding, integrating local colloquialisms", "category_7"),
        SampleRole("a Canadian with deep subject understanding, using Canadian English expressions", "category_8"),
        SampleRole("an advanced ESL student with comprehensive subject knowledge", None),

        # Expert
        SampleRole("a Scottish subject expert integrating Scots dialect", "category_5"),
        SampleRole("a non-native English speaker who is a leading subject expert", None),
        SampleRole("an ESL professor teaching the subject at a postgraduate level with high English proficiency", None),
        SampleRole("a british English speaker who is a renowned subject expert", None),
        SampleRole("a native English speaker from Ireland who is a field leader, using Irish English idioms", "category_9")
    ]

    for goal in sample_goals:
        for style in styles:
            for role in roles:
                # JSON allows to avoid phrases like 'I apologize for any confusion. Here is the correct answer:  '
                # the prompt is categorized to simplify its interpretation using xml-ish syntax
                # the Segments need to be enclosed, it has been observe that the AI just extends the prompt, changing the result
                messages = [
                    {"role": "system", "content": f"You are {role.role} producing sample answers to train an AI."},
                    {"role": "user", "content": f"Please develop an answer for the question '{question.question}'."},
                    {"role": "user", "content": f"{_add_idioms(idioms, role.idiom_category)}"},
                    {"role": "user", "content": f"Write your answer in a {style} as communication style."},
                    {"role": "user", "content": f"The answer should not be longer than two sentences."},
                    {"role": "user", "content": f"Just provide the answer without any additional text."},
                    #{"role": "user", "content": f"Please return your answer as a JSON array: [\"answer\"]"}
                ]

                if question.sample_answer is not None:
                    messages.append({"role": "user", "content": f"Consider '{question.sample_answer}' as sample solution containing all relevant aspects."})

                messages.append({"role": "user", "content": f"{_setup_goal(goal, key_elements)}"})
                yield messages


def _generate_sample(question:Question, prompt) -> List[Answer]:
    prompt_size = _count_token(prompt)
    if prompt_size > 1000:
        log.warning(f"The prompt is very huge: {prompt_size}")
    
    log.debug(f"Create sample answers with the following prompt: {prompt}")

    # Set up parameters for generating answers
    max_tokens = 4000 - prompt_size
    temperature = 0.8
    frequency_penalty = 0.2
    presence_penalty = 0.6

    # Generate answers
    generated_answers = _execute_api_call(
        messages=prompt,
        max_tokens=max_tokens,
        temperature=temperature,
        frequency_penalty=frequency_penalty,
        presence_penalty=presence_penalty
    )

    for choice in generated_answers.choices:
        log.debug(f"generated choice: {choice}")

        message = choice.message['content']
        log.info(f"generated answer: {message}")
        
        answer = message.strip().replace('\n', ' ')
        if answer.startswith("I apologize"):
            index = answer.find(':')
            if index != -1:
                answer = answer[index+1:]
                return [Answer(question.question_id, answer, hashlib.md5(answer.encode()).hexdigest(), -1, -1)]
            log.error(f"Unable to use the answer: {answer}")
        else:
            return [Answer(question.question_id, answer, hashlib.md5(answer.encode()).hexdigest(), -1, -1)]
        


def _validate_rating(rating):
    error_msg = ""
    try:
        rating = int(rating)
        if rating < 0:
            log.error(f"Identified invalid rating: {rating}.")
            return 0
        
        if rating > 3:
            log.error(f"Identified invalid rating: {rating}.")
            return 3

        if rating >= 0 and rating <= 3:
            return rating

    except Exception as e:
        error_msg = f" Error: {str(e)}"

    log.error(f"Identified invalid rating: {rating}. {error_msg}")
    return -1

# We rate multiple answers at once, this is supposed to make ratings more consistent
def generate_rating_prompt(question:Question, numerated_answers, key_elements):
    return [
        {"role": "system", "content": f"You are expert that assess answers to a specific question, based on the presence of distinct key elements"},
        {"role": "user", "content": f"These elements may not be quoted verbatim, but their central meaning should be clearly conveyed in the response."},
        {"role": "user", "content": _add_key_elements(key_elements)},
        {"role": "user", "content": f"""You will classify each answer into categories, depending on the number of key elements it contains from 0 to 3:
    {question.score_offset}: The answer includes none of the key elements.
    {1 + question.score_offset}: The describes includes one key element.
    {2 + question.score_offset}: The describes includes two key elements.
    {3 + question.score_offset}: The describes includes three or more key elements."""},
        {"role": "user", "content": "Keep in mind, the punctuation, stylistic choices, or the specific wording used in an answer do not influence its score."},
        {"role": "user", "content": "The evaluation is solely based on the presence or absence of the key elements."},
        {"role": "user", "content": "The answers will be provided to you in JSON format, such as {{\"answer_id1\":\"answer1\"}}."},
        {"role": "user", "content": "After you assess them, you should provide the scores in a similar JSON format: {{\"answer_id1\":\"rating_id1\"}}."},
        {"role": "user", "content": f"Question: \"{question.question}\""},
        {"role": "user", "content": f"Answers: \"{numerated_answers}\""}
    ]

def _annotate_samples(api_key, question:Question, answers: Iterator[Answer], key_elements:List[KeyElement], score_type:int) -> List[Answer]:
    openai.api_key = api_key
    numerated_rated_answers = {
        f"{idx+1}": answer for idx, answer in enumerate(answers)}

    # map {id:answer} sent to openAi
    numerated_answers = {f"{idx}": answer.answer
                         for idx, answer in numerated_rated_answers.items()}

    messages = generate_rating_prompt(question, numerated_answers, key_elements)
    log.debug(f"Annotate sample answers with the following prompt: {messages}")

    # Set up parameters for generating answers
    max_tokens = 10 * len(answers) # < 10 token / answer {"id":"rating"}
    temperature = 0.4
    frequency_penalty = 0.6
    presence_penalty = 0.2

    # Generate answers
    generated_answers = _execute_api_call(
        messages=messages,
        max_tokens=max_tokens,
        temperature=temperature,
        frequency_penalty=frequency_penalty,
        presence_penalty=presence_penalty
    )
    log.debug(f"Received the following response '{generated_answers}'")

    """for choice in generated_answers.choices:
        log.debug(f"generated choice: {choice}")

        message = choice.message['content']
        log.info(f"generated answer: {message}")"""
    # Extract answers from OpenAI API response
    for choice in generated_answers.choices:
        log.debug(f"generated choice: {choice}")
        message = choice.message['content']

        # remove new lines
        answer = re.sub(r'\n', ' ', message.strip())
        # find json content
        contains_json = re.search(r'\{.*\}', answer)

        if contains_json:
            answer_str = contains_json.group(0).replace("'", '"')
            json_answer = json.loads(answer_str)
            return [_add_rating(numerated_rated_answers, answer_id, rating_id, score_type) for answer_id, rating_id in json_answer.items()]
        raise JSONDecodeError(f"No valid JSON found in answer: {answer}")

def annotate_samples(api_key, question:Question, answers: Iterator[Answer], key_elements:List[KeyElement]) -> Generator[List[Answer], None, None]:
    retry = 0
    max_retries = 5
    while retry < max_retries:
        try:
            log.debug(f"Try to rate answers with retry number: {retry}")
            # rate score_1 and score_2
            rated_answers = _annotate_samples(api_key, question, answers, key_elements, 1)
            yield _annotate_samples(api_key, question, rated_answers, key_elements, 2)
            break
        except JSONDecodeError as e:
            retry += 1
            log.error(
                f"Unable to parse JSON response: {e}")
        except Exception as e:
            retry += 1
            log.error(
                f"Unable to rate Answer: {e}")

    if retry >= max_retries: 
        log.error(f"Exceeded {retry} retries, the rating of answers will be aborted")

        

def _add_rating(numerated_rated_answers, answer_id, rating_id, score_type):
    original_answer = numerated_rated_answers[answer_id]
    log.debug(f"Validate rating: {rating_id} for answer_id: {answer_id} and score_type: {score_type}")
    if score_type == 1:
        original_answer.score_1 = _validate_rating(rating_id)
    else:
        original_answer.score_2 = _validate_rating(rating_id)

    return original_answer